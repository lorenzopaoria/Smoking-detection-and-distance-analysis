{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/cigarettes_model_load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlHaWLsYPeim"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Rhxpa2Peio",
        "outputId": "1c35713e-094f-44b8-926c-417d14b538ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGwp0XLLPeip"
      },
      "outputs": [],
      "source": [
        "def load_model(model_path):\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn(weights=models.detection.FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    num_classes = 2\n",
        "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "    model.eval()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bWu1hEzPeip"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, image, threshold=0.5):\n",
        "    transform = transforms.ToTensor()\n",
        "    image_tensor = transform(image).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(image_tensor)\n",
        "\n",
        "    boxes = predictions[0]['boxes']\n",
        "    scores = predictions[0]['scores']\n",
        "    labels = predictions[0]['labels']\n",
        "\n",
        "    keep = scores > threshold\n",
        "    boxes = boxes[keep]\n",
        "    labels = labels[keep]\n",
        "    scores = scores[keep]\n",
        "    return boxes, labels, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9_ejZv_Peiq"
      },
      "outputs": [],
      "source": [
        "def draw_boxes(image, boxes, labels, scores):\n",
        "    # Convert PIL Image to numpy array in RGB format\n",
        "    image_np = np.array(image)\n",
        "    \n",
        "    # Convert RGB to BGR for OpenCV\n",
        "    image_cv = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n",
        "    \n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        x1, y1, x2, y2 = box.tolist()\n",
        "        # Draw red bounding box\n",
        "        cv2.rectangle(image_cv, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
        "        \n",
        "        # Prepare label text with confidence score\n",
        "        label_text = f\"Cigarette: {score:.2f}\"\n",
        "        \n",
        "        # Calculate text size and position\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.6\n",
        "        thickness = 2\n",
        "        (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, thickness)\n",
        "        \n",
        "        # Draw background rectangle for text\n",
        "        cv2.rectangle(image_cv, \n",
        "                    (int(x1), int(y1) - text_height - 5),\n",
        "                    (int(x1) + text_width, int(y1)),\n",
        "                    (0, 0, 255),\n",
        "                    -1)  # Filled rectangle\n",
        "        \n",
        "        # Add white text\n",
        "        cv2.putText(image_cv,\n",
        "                    label_text,\n",
        "                    (int(x1), int(y1) - 5),\n",
        "                    font,\n",
        "                    font_scale,\n",
        "                    (255, 255, 255),  # White color\n",
        "                    thickness)\n",
        "    \n",
        "    return image_cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_FnjXW_Peiq"
      },
      "outputs": [],
      "source": [
        "def process_images(model_path, images_folder, output_folder):\n",
        "    model = load_model(model_path)\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Get list of image files\n",
        "    image_files = [f for f in os.listdir(images_folder) \n",
        "                if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "    \n",
        "    # Create progress bar\n",
        "    for image_name in tqdm(image_files, desc=\"Processing images\"):\n",
        "        image_path = os.path.join(images_folder, image_name)\n",
        "        \n",
        "        # Load image in RGB format\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        boxes, labels, scores = get_predictions(model, image)\n",
        "\n",
        "        # Draw boxes and save\n",
        "        result_image = draw_boxes(image, boxes, labels, scores)\n",
        "        result_image_path = os.path.join(output_folder, f\"output_{image_name}\")\n",
        "        cv2.imwrite(result_image_path, result_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYEPq5s3Peiq",
        "outputId": "eafbc06b-e243-40e3-942d-1b8f569467c7"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    model_path = '/content/drive/MyDrive/pth_cigarette_detect/fasterrcnn_cigarette_final.pth'\n",
        "    images_folder = '/content/drive/MyDrive/Photo/test'\n",
        "    output_folder = '/content/drive/MyDrive/test_trained'\n",
        "\n",
        "    process_images(model_path, images_folder, output_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
