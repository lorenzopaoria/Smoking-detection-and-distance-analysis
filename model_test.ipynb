{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zPN1xKa_0qbApVgPxQCp_0QfaaFNmul5",
      "authorship_tag": "ABX9TyMr9RJj4STterZW2eVwysIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2hhcAycr4fy9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision.ops import nms\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUVkgkFH6uBJ",
        "outputId": "f50132da-4733-4a70-b8e8-0ae7db098ce8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES = [\"sigarette\", \"smoker\", \"non_smoker\"]\n",
        "NUM_CLASSES = len(CLASS_NAMES) + 1\n",
        "MODEL_PATH = '/content/drive/MyDrive/pth_epoch/model_epoch_10.pth'\n",
        "TEST_DIR = '/content/drive/MyDrive/Photo/test'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/test_trained'\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "ydFnSyXa4kRH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
        "\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
        "        in_features, NUM_CLASSES)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VR6zNMPIYbkf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    \"\"\"Carica il modello salvato\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Il file del modello non esiste: {model_path}\")\n",
        "\n",
        "    print(f\"Caricamento del modello da {model_path}\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Utilizzo device: {device}\")\n",
        "\n",
        "    try:\n",
        "        model = get_model()\n",
        "\n",
        "        state_dict = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "        model.eval()\n",
        "        print(\"Modello caricato con successo\")\n",
        "        return model, device\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nel caricamento del modello: {str(e)}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "vcQ4UXcgYlxG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, test_dir, transform=None):\n",
        "        self.test_dir = Path(test_dir)\n",
        "        if not self.test_dir.exists():\n",
        "            raise FileNotFoundError(f\"La directory {test_dir} non esiste!\")\n",
        "\n",
        "        self.image_files = list(self.test_dir.glob('*.[jp][pn][g]'))\n",
        "        if not self.image_files:\n",
        "            raise FileNotFoundError(f\"Nessuna immagine trovata in {test_dir}\")\n",
        "\n",
        "        print(f\"Trovate {len(self.image_files)} immagini in {test_dir}\")\n",
        "\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((800, 800)),  # Dimensione standard per Faster R-CNN\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])  # Normalizzazione ImageNet\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = str(self.image_files[idx])\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, img_path\n",
        "        except Exception as e:\n",
        "            print(f\"Errore nel caricamento dell'immagine {img_path}: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "iYnf8CVW4rHA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_predictions(image, boxes, labels, scores, output_path):\n",
        "    \"\"\"Disegna le bounding box sulle immagini e salva il risultato\"\"\"\n",
        "    try:\n",
        "        # Denormalizza l'immagine\n",
        "        image = image * torch.tensor([0.229, 0.224, 0.225])[:, None, None]\n",
        "        image = image + torch.tensor([0.485, 0.456, 0.406])[:, None, None]\n",
        "        image = (image * 255).byte()\n",
        "\n",
        "        # Colori per le diverse classi\n",
        "        colors = [\"red\", \"green\", \"blue\"]\n",
        "\n",
        "        # Crea le etichette con classe e score\n",
        "        labels_text = [f\"{CLASS_NAMES[int(l)-1]}: {s:.2f}\" for l, s in zip(labels, scores)]\n",
        "\n",
        "        # Disegna le bounding box\n",
        "        image_with_boxes = draw_bounding_boxes(\n",
        "            image,\n",
        "            boxes,\n",
        "            labels=labels_text,\n",
        "            colors=colors,\n",
        "            width=2\n",
        "        )\n",
        "\n",
        "        # Converti in formato PIL e salva\n",
        "        image_with_boxes = image_with_boxes.permute(1, 2, 0).numpy()\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(image_with_boxes)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"Salvata immagine con predizioni in {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nel disegno delle predizioni: {str(e)}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "D85bn-C_4-i5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, device, test_loader):\n",
        "    \"\"\"Valuta il modello e salva le immagini con le predizioni\"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"Inizio valutazione del modello...\")\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_paths) in enumerate(test_loader):\n",
        "            print(f\"\\nProcessing batch {i+1}/{len(test_loader)}\")\n",
        "\n",
        "            try:\n",
        "                images = images.to(device)\n",
        "                predictions = model(images)\n",
        "\n",
        "                for j, (prediction, img_path) in enumerate(zip(predictions, img_paths)):\n",
        "                    boxes = prediction['boxes']\n",
        "                    scores = prediction['scores']\n",
        "                    labels = prediction['labels']\n",
        "\n",
        "                    # Filtra le predizioni con score > 0.5\n",
        "                    mask = scores > 0.5\n",
        "                    boxes = boxes[mask]\n",
        "                    scores = scores[mask]\n",
        "                    labels = labels[mask]\n",
        "\n",
        "                    if len(boxes) > 0:\n",
        "                        base_name = os.path.basename(img_path)\n",
        "                        output_filename = f\"pred_{base_name}\"\n",
        "                        output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
        "\n",
        "                        draw_predictions(\n",
        "                            images[j].cpu(),\n",
        "                            boxes.cpu(),\n",
        "                            labels.cpu(),\n",
        "                            scores.cpu(),\n",
        "                            output_path\n",
        "                        )\n",
        "\n",
        "                        print(f\"Processata immagine: {base_name}\")\n",
        "                    else:\n",
        "                        print(f\"Nessuna predizione sopra la soglia per {os.path.basename(img_path)}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Errore nel processing del batch {i+1}: {str(e)}\")\n",
        "                continue"
      ],
      "metadata": {
        "id": "L7w33YdZV7OG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Inizializzazione...\")\n",
        "\n",
        "        # Crea la directory di output se non esiste\n",
        "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "        # Verifica l'esistenza delle directory\n",
        "        for path in [os.path.dirname(MODEL_PATH), TEST_DIR]:\n",
        "            if not os.path.exists(path):\n",
        "                raise FileNotFoundError(f\"Directory non trovata: {path}\")\n",
        "\n",
        "        # Crea il dataset di test\n",
        "        print(\"\\nCreazione dataset di test...\")\n",
        "        test_dataset = TestDataset(TEST_DIR)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "        # Carica il modello\n",
        "        print(\"\\nCaricamento modello...\")\n",
        "        model, device = load_model(MODEL_PATH)\n",
        "\n",
        "        # Esegui la valutazione\n",
        "        print(\"\\nInizio valutazione...\")\n",
        "        evaluate_model(model, device, test_loader)\n",
        "\n",
        "        print(\"\\nProcessing completato con successo!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nErrore durante l'esecuzione: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHreuuOI5BbC",
        "outputId": "0328a426-14d4-4f3f-da08-ca29f112ecaf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizializzazione...\n",
            "\n",
            "Creazione dataset di test...\n",
            "Trovate 73 immagini in /content/drive/MyDrive/Photo/test\n",
            "\n",
            "Caricamento modello...\n",
            "Caricamento del modello da /content/drive/MyDrive/pth_epoch/model_epoch_10.pth\n",
            "Utilizzo device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 58.8MB/s]\n",
            "<ipython-input-15-4389a666b82e>:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore nel caricamento del modello: Error(s) in loading state_dict for FasterRCNN:\n",
            "\tMissing key(s) in state_dict: \"backbone.body.conv1.weight\", \"backbone.body.bn1.weight\", \"backbone.body.bn1.bias\", \"backbone.body.bn1.running_mean\", \"backbone.body.bn1.running_var\", \"backbone.body.layer1.0.conv1.weight\", \"backbone.body.layer1.0.bn1.weight\", \"backbone.body.layer1.0.bn1.bias\", \"backbone.body.layer1.0.bn1.running_mean\", \"backbone.body.layer1.0.bn1.running_var\", \"backbone.body.layer1.0.conv2.weight\", \"backbone.body.layer1.0.bn2.weight\", \"backbone.body.layer1.0.bn2.bias\", \"backbone.body.layer1.0.bn2.running_mean\", \"backbone.body.layer1.0.bn2.running_var\", \"backbone.body.layer1.0.conv3.weight\", \"backbone.body.layer1.0.bn3.weight\", \"backbone.body.layer1.0.bn3.bias\", \"backbone.body.layer1.0.bn3.running_mean\", \"backbone.body.layer1.0.bn3.running_var\", \"backbone.body.layer1.0.downsample.0.weight\", \"backbone.body.layer1.0.downsample.1.weight\", \"backbone.body.layer1.0.downsample.1.bias\", \"backbone.body.layer1.0.downsample.1.running_mean\", \"backbone.body.layer1.0.downsample.1.running_var\", \"backbone.body.layer1.1.conv1.weight\", \"backbone.body.layer1.1.bn1.weight\", \"backbone.body.layer1.1.bn1.bias\", \"backbone.body.layer1.1.bn1.running_mean\", \"backbone.body.layer1.1.bn1.running_var\", \"backbone.body.layer1.1.conv2.weight\", \"backbone.body.layer1.1.bn2.weight\", \"backbone.body.layer1.1.bn2.bias\", \"backbone.body.layer1.1.bn2.running_mean\", \"backbone.body.layer1.1.bn2.running_var\", \"backbone.body.layer1.1.conv3.weight\", \"backbone.body.layer1.1.bn3.weight\", \"backbone.body.layer1.1.bn3.bias\", \"backbone.body.layer1.1.bn3.running_mean\", \"backbone.body.layer1.1.bn3.running_var\", \"backbone.body.layer1.2.conv1.weight\", \"backbone.body.layer1.2.bn1.weight\", \"backbone.body.layer1.2.bn1.bias\", \"backbone.body.layer1.2.bn1.running_mean\", \"backbone.body.layer1.2.bn1.running_var\", \"backbone.body.layer1.2.conv2.weight\", \"backbone.body.layer1.2.bn2.weight\", \"backbone.body.layer1.2.bn2.bias\", \"backbone.body.layer1.2.bn2.running_mean\", \"backbone.body.layer1.2.bn2.running_var\", \"backbone.body.layer1.2.conv3.weight\", \"backbone.body.layer1.2.bn3.weight\", \"backbone.body.layer1.2.bn3.bias\", \"backbone.body.layer1.2.bn3.running_mean\", \"backbone.body.layer1.2.bn3.running_var\", \"backbone.body.layer2.0.conv1.weight\", \"backbone.body.layer2.0.bn1.weight\", \"backbone.body.layer2.0.bn1.bias\", \"backbone.body.layer2.0.bn1.running_mean\", \"backbone.body.layer2.0.bn1.running_var\", \"backbone.body.layer2.0.conv2.weight\", \"backbone.body.layer2.0.bn2.weight\", \"backbone.body.layer2.0.bn2.bias\", \"backbone.body.layer2.0.bn2.running_mean\", \"backbone.body.layer2.0.bn2.running_var\", \"backbone.body.layer2.0.conv3.weight\", \"backbone.body.layer2.0.bn3.weight\", \"backbone.body.layer2.0.bn3.bias\", \"backbone.body.layer2.0.bn3.running_mean\", \"backbone.body.layer2.0.bn3.running_var\", \"backbone.body.layer2.0.downsample.0.weight\", \"backbone.body.layer2.0.downsample.1.weight\", \"backbone.body.layer2.0.downsample.1.bias\", \"backbone.body.layer2.0.downsample.1.running_mean\", \"backbone.body.layer2.0.downsample.1.running_var\", \"backbone.body.layer2.1.conv1.weight\", \"backbone.body.layer2.1.bn1.weight\", \"backbone.body.layer2.1.bn1.bias\", \"backbone.body.layer2.1.bn1.running_mean\", \"backbone.body.layer2.1.bn1.running_var\", \"backbone.body.layer2.1.conv2.weight\", \"backbone.body.layer2.1.bn2.weight\", \"backbone.body.layer2.1.bn2.bias\", \"backbone.body.layer2.1.bn2.running_mean\", \"backbone.body.layer2.1.bn2.running_var\", \"backbone.body.layer2.1.conv3.weight\", \"backbone.body.layer2.1.bn3.weight\", \"backbone.body.layer2.1.bn3.bias\", \"backbone.body.layer2.1.bn3.running_mean\", \"backbone.body.layer2.1.bn3.running_var\", \"backbone.body.layer2.2.conv1.weight\", \"backbone.body.layer2.2.bn1.weight\", \"backbone.body.layer2.2.bn1.bias\", \"backbone.body.layer2.2.bn1.running_mean\", \"backbone.body.layer2.2.bn1.running_var\", \"backbone.body.layer2.2.conv2.weight\", \"backbone.body.layer2.2.bn2.weight\", \"backbone.body.layer2.2.bn2.bias\", \"backbone.body.layer2.2.bn2.running_mean\", \"backbone.body.layer2.2.bn2.running_var\", \"backbone.body.layer2.2.conv3.weight\", \"backbone.body.layer2.2.bn3.weight\", \"backbone.body.layer2.2.bn3.bias\", \"backbone.body.layer2.2.bn3.running_mean\", \"backbone.body.layer2.2.bn3.running_var\", \"backbone.body.layer2.3.conv1.weight\", \"backbone.body.layer2.3.bn1.weight\", \"backbone.body.layer2.3.bn1.bias\", \"backbone.body.layer2.3.bn1.running_mean\", \"backbone.body.layer2.3.bn1.running_var\", \"backbone.body.layer2.3.conv2.weight\", \"backbone.body.layer2.3.bn2.weight\", \"backbone.body.layer2.3.bn2.bias\", \"backbone.body.layer2.3.bn2.running_mean\", \"backbone.body.layer2.3.bn2.running_var\", \"backbone.body.layer2.3.conv3.weight\", \"backbone.body.layer2.3.bn3.weight\", \"backbone.body.layer2.3.bn3.bias\", \"backbone.body.layer2.3.bn3.running_mean\", \"backbone.body.layer2.3.bn3.running_var\", \"backbone.body.layer3.0.conv1.weight\", \"backbone.body.layer3.0.bn1.weight\", \"backbone.body.layer3.0.bn1.bias\", \"backbone.body.layer3.0.bn1.running_mean\", \"backbone.body.layer3.0.bn1.running_var\", \"backbone.body.layer3.0.conv2.weight\", \"backbone.body.layer3.0.bn2.weight\", \"backbone.body.layer3.0.bn2.bias\", \"backbone.body.layer3.0.bn2.running_mean\", \"backbone.body.layer3.0.bn2.running_var\", \"backbone.body.layer3.0.conv3.weight\", \"backbone.body.layer3.0.bn3.weight\", \"backbone.body.layer3.0.bn3.bias\", \"backbone.body.layer3.0.bn3.running_mean\", \"backbone.body.layer3.0.bn3.running_var\", \"backbone.body.layer3.0.downsample.0.weight\", \"backbone.body.layer3.0.downsample.1.weight\", \"backbone.body.layer3.0.downsample.1.bias\", \"backbone.body.layer3.0.downsample.1.running_mean\", \"backbone.body.layer3.0.downsample.1.running_var\", \"backbone.body.layer3.1.conv1.weight\", \"backbone.body.layer3.1.bn1.weight\", \"backbone.body.layer3.1.bn1.bias\", \"backbone.body.layer3.1.bn1.running_mean\", \"backbone.body.layer3.1.bn1.running_var\", \"backbone.body.layer3.1.conv2.weight\", \"backbone.body.layer3.1.bn2.weight\", \"backbone.body.layer3.1.bn2.bias\", \"backbone.body.layer3.1.bn2.running_mean\", \"backbone.body.layer3.1.bn2.running_var\", \"backbone.body.layer3.1.conv3.weight\", \"backbone.body.layer3.1.bn3.weight\", \"backbone.body.layer3.1.bn3.bias\", \"backbone.body.layer3.1.bn3.running_mean\", \"backbone.body.layer3.1.bn3.running_var\", \"backbone.body.layer3.2.conv1.weight\", \"backbone.body.layer3.2.bn1.weight\", \"backbone.body.layer3.2.bn1.bias\", \"backbone.body.layer3.2.bn1.running_mean\", \"backbone.body.layer3.2.bn1.running_var\", \"backbone.body.layer3.2.conv2.weight\", \"backbone.body.layer3.2.bn2.weight\", \"backbone.body.layer3.2.bn2.bias\", \"backbone.body.layer3.2.bn2.running_mean\", \"backbone.body.layer3.2.bn2.running_var\", \"backbone.body.layer3.2.conv3.weight\", \"backbone.body.layer3.2.bn3.weight\", \"backbone.body.layer3.2.bn3.bias\", \"backbone.body.layer3.2.bn3.running_mean\", \"backbone.body.layer3.2.bn3.running_var\", \"backbone.body.layer3.3.conv1.weight\", \"backbone.body.layer3.3.bn1.weight\", \"backbone.body.layer3.3.bn1.bias\", \"backbone.body.layer3.3.bn1.running_mean\", \"backbone.body.layer3.3.bn1.running_var\", \"backbone.body.layer3.3.conv2.weight\", \"backbone.body.layer3.3.bn2.weight\", \"backbone.body.layer3.3.bn2.bias\", \"backbone.body.layer3.3.bn2.running_mean\", \"backbone.body.layer3.3.bn2.running_var\", \"backbone.body.layer3.3.conv3.weight\", \"backbone.body.layer3.3.bn3.weight\", \"backbone.body.layer3.3.bn3.bias\", \"backbone.body.layer3.3.bn3.running_mean\", \"backbone.body.layer3.3.bn3.running_var\", \"backbone.body.layer3.4.conv1.weight\", \"backbone.body.layer3.4.bn1.weight\", \"backbone.body.layer3.4.bn1.bias\", \"backbone.body.layer3.4.bn1.running_mean\", \"backbone.body.layer3.4.bn1.running_var\", \"backbone.body.layer3.4.conv2.weight\", \"backbone.body.layer3.4.bn2.weight\", \"backbone.body.layer3.4.bn2.bias\", \"backbone.body.layer3.4.bn2.running_mean\", \"backbone.body.layer3.4.bn2.running_var\", \"backbone.body.layer3.4.conv3.weight\", \"backbone.body.layer3.4.bn3.weight\", \"backbone.body.layer3.4.bn3.bias\", \"backbone.body.layer3.4.bn3.running_mean\", \"backbone.body.layer3.4.bn3.running_var\", \"backbone.body.layer3.5.conv1.weight\", \"backbone.body.layer3.5.bn1.weight\", \"backbone.body.layer3.5.bn1.bias\", \"backbone.body.layer3.5.bn1.running_mean\", \"backbone.body.layer3.5.bn1.running_var\", \"backbone.body.layer3.5.conv2.weight\", \"backbone.body.layer3.5.bn2.weight\", \"backbone.body.layer3.5.bn2.bias\", \"backbone.body.layer3.5.bn2.running_mean\", \"backbone.body.layer3.5.bn2.running_var\", \"backbone.body.layer3.5.conv3.weight\", \"backbone.body.layer3.5.bn3.weight\", \"backbone.body.layer3.5.bn3.bias\", \"backbone.body.layer3.5.bn3.running_mean\", \"backbone.body.layer3.5.bn3.running_var\", \"backbone.body.layer4.0.conv1.weight\", \"backbone.body.layer4.0.bn1.weight\", \"backbone.body.layer4.0.bn1.bias\", \"backbone.body.layer4.0.bn1.running_mean\", \"backbone.body.layer4.0.bn1.running_var\", \"backbone.body.layer4.0.conv2.weight\", \"backbone.body.layer4.0.bn2.weight\", \"backbone.body.layer4.0.bn2.bias\", \"backbone.body.layer4.0.bn2.running_mean\", \"backbone.body.layer4.0.bn2.running_var\", \"backbone.body.layer4.0.conv3.weight\", \"backbone.body.layer4.0.bn3.weight\", \"backbone.body.layer4.0.bn3.bias\", \"backbone.body.layer4.0.bn3.running_mean\", \"backbone.body.layer4.0.bn3.running_var\", \"backbone.body.layer4.0.downsample.0.weight\", \"backbone.body.layer4.0.downsample.1.weight\", \"backbone.body.layer4.0.downsample.1.bias\", \"backbone.body.layer4.0.downsample.1.running_mean\", \"backbone.body.layer4.0.downsample.1.running_var\", \"backbone.body.layer4.1.conv1.weight\", \"backbone.body.layer4.1.bn1.weight\", \"backbone.body.layer4.1.bn1.bias\", \"backbone.body.layer4.1.bn1.running_mean\", \"backbone.body.layer4.1.bn1.running_var\", \"backbone.body.layer4.1.conv2.weight\", \"backbone.body.layer4.1.bn2.weight\", \"backbone.body.layer4.1.bn2.bias\", \"backbone.body.layer4.1.bn2.running_mean\", \"backbone.body.layer4.1.bn2.running_var\", \"backbone.body.layer4.1.conv3.weight\", \"backbone.body.layer4.1.bn3.weight\", \"backbone.body.layer4.1.bn3.bias\", \"backbone.body.layer4.1.bn3.running_mean\", \"backbone.body.layer4.1.bn3.running_var\", \"backbone.body.layer4.2.conv1.weight\", \"backbone.body.layer4.2.bn1.weight\", \"backbone.body.layer4.2.bn1.bias\", \"backbone.body.layer4.2.bn1.running_mean\", \"backbone.body.layer4.2.bn1.running_var\", \"backbone.body.layer4.2.conv2.weight\", \"backbone.body.layer4.2.bn2.weight\", \"backbone.body.layer4.2.bn2.bias\", \"backbone.body.layer4.2.bn2.running_mean\", \"backbone.body.layer4.2.bn2.running_var\", \"backbone.body.layer4.2.conv3.weight\", \"backbone.body.layer4.2.bn3.weight\", \"backbone.body.layer4.2.bn3.bias\", \"backbone.body.layer4.2.bn3.running_mean\", \"backbone.body.layer4.2.bn3.running_var\", \"backbone.fpn.inner_blocks.0.0.weight\", \"backbone.fpn.inner_blocks.0.0.bias\", \"backbone.fpn.inner_blocks.1.0.weight\", \"backbone.fpn.inner_blocks.1.0.bias\", \"backbone.fpn.inner_blocks.2.0.weight\", \"backbone.fpn.inner_blocks.2.0.bias\", \"backbone.fpn.inner_blocks.3.0.weight\", \"backbone.fpn.inner_blocks.3.0.bias\", \"backbone.fpn.layer_blocks.0.0.weight\", \"backbone.fpn.layer_blocks.0.0.bias\", \"backbone.fpn.layer_blocks.1.0.weight\", \"backbone.fpn.layer_blocks.1.0.bias\", \"backbone.fpn.layer_blocks.2.0.weight\", \"backbone.fpn.layer_blocks.2.0.bias\", \"backbone.fpn.layer_blocks.3.0.weight\", \"backbone.fpn.layer_blocks.3.0.bias\", \"rpn.head.conv.0.0.weight\", \"rpn.head.conv.0.0.bias\", \"rpn.head.cls_logits.weight\", \"rpn.head.cls_logits.bias\", \"rpn.head.bbox_pred.weight\", \"rpn.head.bbox_pred.bias\", \"roi_heads.box_head.fc6.weight\", \"roi_heads.box_head.fc6.bias\", \"roi_heads.box_head.fc7.weight\", \"roi_heads.box_head.fc7.bias\", \"roi_heads.box_predictor.cls_score.weight\", \"roi_heads.box_predictor.cls_score.bias\", \"roi_heads.box_predictor.bbox_pred.weight\", \"roi_heads.box_predictor.bbox_pred.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". \n",
            "\n",
            "Errore durante l'esecuzione: Error(s) in loading state_dict for FasterRCNN:\n",
            "\tMissing key(s) in state_dict: \"backbone.body.conv1.weight\", \"backbone.body.bn1.weight\", \"backbone.body.bn1.bias\", \"backbone.body.bn1.running_mean\", \"backbone.body.bn1.running_var\", \"backbone.body.layer1.0.conv1.weight\", \"backbone.body.layer1.0.bn1.weight\", \"backbone.body.layer1.0.bn1.bias\", \"backbone.body.layer1.0.bn1.running_mean\", \"backbone.body.layer1.0.bn1.running_var\", \"backbone.body.layer1.0.conv2.weight\", \"backbone.body.layer1.0.bn2.weight\", \"backbone.body.layer1.0.bn2.bias\", \"backbone.body.layer1.0.bn2.running_mean\", \"backbone.body.layer1.0.bn2.running_var\", \"backbone.body.layer1.0.conv3.weight\", \"backbone.body.layer1.0.bn3.weight\", \"backbone.body.layer1.0.bn3.bias\", \"backbone.body.layer1.0.bn3.running_mean\", \"backbone.body.layer1.0.bn3.running_var\", \"backbone.body.layer1.0.downsample.0.weight\", \"backbone.body.layer1.0.downsample.1.weight\", \"backbone.body.layer1.0.downsample.1.bias\", \"backbone.body.layer1.0.downsample.1.running_mean\", \"backbone.body.layer1.0.downsample.1.running_var\", \"backbone.body.layer1.1.conv1.weight\", \"backbone.body.layer1.1.bn1.weight\", \"backbone.body.layer1.1.bn1.bias\", \"backbone.body.layer1.1.bn1.running_mean\", \"backbone.body.layer1.1.bn1.running_var\", \"backbone.body.layer1.1.conv2.weight\", \"backbone.body.layer1.1.bn2.weight\", \"backbone.body.layer1.1.bn2.bias\", \"backbone.body.layer1.1.bn2.running_mean\", \"backbone.body.layer1.1.bn2.running_var\", \"backbone.body.layer1.1.conv3.weight\", \"backbone.body.layer1.1.bn3.weight\", \"backbone.body.layer1.1.bn3.bias\", \"backbone.body.layer1.1.bn3.running_mean\", \"backbone.body.layer1.1.bn3.running_var\", \"backbone.body.layer1.2.conv1.weight\", \"backbone.body.layer1.2.bn1.weight\", \"backbone.body.layer1.2.bn1.bias\", \"backbone.body.layer1.2.bn1.running_mean\", \"backbone.body.layer1.2.bn1.running_var\", \"backbone.body.layer1.2.conv2.weight\", \"backbone.body.layer1.2.bn2.weight\", \"backbone.body.layer1.2.bn2.bias\", \"backbone.body.layer1.2.bn2.running_mean\", \"backbone.body.layer1.2.bn2.running_var\", \"backbone.body.layer1.2.conv3.weight\", \"backbone.body.layer1.2.bn3.weight\", \"backbone.body.layer1.2.bn3.bias\", \"backbone.body.layer1.2.bn3.running_mean\", \"backbone.body.layer1.2.bn3.running_var\", \"backbone.body.layer2.0.conv1.weight\", \"backbone.body.layer2.0.bn1.weight\", \"backbone.body.layer2.0.bn1.bias\", \"backbone.body.layer2.0.bn1.running_mean\", \"backbone.body.layer2.0.bn1.running_var\", \"backbone.body.layer2.0.conv2.weight\", \"backbone.body.layer2.0.bn2.weight\", \"backbone.body.layer2.0.bn2.bias\", \"backbone.body.layer2.0.bn2.running_mean\", \"backbone.body.layer2.0.bn2.running_var\", \"backbone.body.layer2.0.conv3.weight\", \"backbone.body.layer2.0.bn3.weight\", \"backbone.body.layer2.0.bn3.bias\", \"backbone.body.layer2.0.bn3.running_mean\", \"backbone.body.layer2.0.bn3.running_var\", \"backbone.body.layer2.0.downsample.0.weight\", \"backbone.body.layer2.0.downsample.1.weight\", \"backbone.body.layer2.0.downsample.1.bias\", \"backbone.body.layer2.0.downsample.1.running_mean\", \"backbone.body.layer2.0.downsample.1.running_var\", \"backbone.body.layer2.1.conv1.weight\", \"backbone.body.layer2.1.bn1.weight\", \"backbone.body.layer2.1.bn1.bias\", \"backbone.body.layer2.1.bn1.running_mean\", \"backbone.body.layer2.1.bn1.running_var\", \"backbone.body.layer2.1.conv2.weight\", \"backbone.body.layer2.1.bn2.weight\", \"backbone.body.layer2.1.bn2.bias\", \"backbone.body.layer2.1.bn2.running_mean\", \"backbone.body.layer2.1.bn2.running_var\", \"backbone.body.layer2.1.conv3.weight\", \"backbone.body.layer2.1.bn3.weight\", \"backbone.body.layer2.1.bn3.bias\", \"backbone.body.layer2.1.bn3.running_mean\", \"backbone.body.layer2.1.bn3.running_var\", \"backbone.body.layer2.2.conv1.weight\", \"backbone.body.layer2.2.bn1.weight\", \"backbone.body.layer2.2.bn1.bias\", \"backbone.body.layer2.2.bn1.running_mean\", \"backbone.body.layer2.2.bn1.running_var\", \"backbone.body.layer2.2.conv2.weight\", \"backbone.body.layer2.2.bn2.weight\", \"backbone.body.layer2.2.bn2.bias\", \"backbone.body.layer2.2.bn2.running_mean\", \"backbone.body.layer2.2.bn2.running_var\", \"backbone.body.layer2.2.conv3.weight\", \"backbone.body.layer2.2.bn3.weight\", \"backbone.body.layer2.2.bn3.bias\", \"backbone.body.layer2.2.bn3.running_mean\", \"backbone.body.layer2.2.bn3.running_var\", \"backbone.body.layer2.3.conv1.weight\", \"backbone.body.layer2.3.bn1.weight\", \"backbone.body.layer2.3.bn1.bias\", \"backbone.body.layer2.3.bn1.running_mean\", \"backbone.body.layer2.3.bn1.running_var\", \"backbone.body.layer2.3.conv2.weight\", \"backbone.body.layer2.3.bn2.weight\", \"backbone.body.layer2.3.bn2.bias\", \"backbone.body.layer2.3.bn2.running_mean\", \"backbone.body.layer2.3.bn2.running_var\", \"backbone.body.layer2.3.conv3.weight\", \"backbone.body.layer2.3.bn3.weight\", \"backbone.body.layer2.3.bn3.bias\", \"backbone.body.layer2.3.bn3.running_mean\", \"backbone.body.layer2.3.bn3.running_var\", \"backbone.body.layer3.0.conv1.weight\", \"backbone.body.layer3.0.bn1.weight\", \"backbone.body.layer3.0.bn1.bias\", \"backbone.body.layer3.0.bn1.running_mean\", \"backbone.body.layer3.0.bn1.running_var\", \"backbone.body.layer3.0.conv2.weight\", \"backbone.body.layer3.0.bn2.weight\", \"backbone.body.layer3.0.bn2.bias\", \"backbone.body.layer3.0.bn2.running_mean\", \"backbone.body.layer3.0.bn2.running_var\", \"backbone.body.layer3.0.conv3.weight\", \"backbone.body.layer3.0.bn3.weight\", \"backbone.body.layer3.0.bn3.bias\", \"backbone.body.layer3.0.bn3.running_mean\", \"backbone.body.layer3.0.bn3.running_var\", \"backbone.body.layer3.0.downsample.0.weight\", \"backbone.body.layer3.0.downsample.1.weight\", \"backbone.body.layer3.0.downsample.1.bias\", \"backbone.body.layer3.0.downsample.1.running_mean\", \"backbone.body.layer3.0.downsample.1.running_var\", \"backbone.body.layer3.1.conv1.weight\", \"backbone.body.layer3.1.bn1.weight\", \"backbone.body.layer3.1.bn1.bias\", \"backbone.body.layer3.1.bn1.running_mean\", \"backbone.body.layer3.1.bn1.running_var\", \"backbone.body.layer3.1.conv2.weight\", \"backbone.body.layer3.1.bn2.weight\", \"backbone.body.layer3.1.bn2.bias\", \"backbone.body.layer3.1.bn2.running_mean\", \"backbone.body.layer3.1.bn2.running_var\", \"backbone.body.layer3.1.conv3.weight\", \"backbone.body.layer3.1.bn3.weight\", \"backbone.body.layer3.1.bn3.bias\", \"backbone.body.layer3.1.bn3.running_mean\", \"backbone.body.layer3.1.bn3.running_var\", \"backbone.body.layer3.2.conv1.weight\", \"backbone.body.layer3.2.bn1.weight\", \"backbone.body.layer3.2.bn1.bias\", \"backbone.body.layer3.2.bn1.running_mean\", \"backbone.body.layer3.2.bn1.running_var\", \"backbone.body.layer3.2.conv2.weight\", \"backbone.body.layer3.2.bn2.weight\", \"backbone.body.layer3.2.bn2.bias\", \"backbone.body.layer3.2.bn2.running_mean\", \"backbone.body.layer3.2.bn2.running_var\", \"backbone.body.layer3.2.conv3.weight\", \"backbone.body.layer3.2.bn3.weight\", \"backbone.body.layer3.2.bn3.bias\", \"backbone.body.layer3.2.bn3.running_mean\", \"backbone.body.layer3.2.bn3.running_var\", \"backbone.body.layer3.3.conv1.weight\", \"backbone.body.layer3.3.bn1.weight\", \"backbone.body.layer3.3.bn1.bias\", \"backbone.body.layer3.3.bn1.running_mean\", \"backbone.body.layer3.3.bn1.running_var\", \"backbone.body.layer3.3.conv2.weight\", \"backbone.body.layer3.3.bn2.weight\", \"backbone.body.layer3.3.bn2.bias\", \"backbone.body.layer3.3.bn2.running_mean\", \"backbone.body.layer3.3.bn2.running_var\", \"backbone.body.layer3.3.conv3.weight\", \"backbone.body.layer3.3.bn3.weight\", \"backbone.body.layer3.3.bn3.bias\", \"backbone.body.layer3.3.bn3.running_mean\", \"backbone.body.layer3.3.bn3.running_var\", \"backbone.body.layer3.4.conv1.weight\", \"backbone.body.layer3.4.bn1.weight\", \"backbone.body.layer3.4.bn1.bias\", \"backbone.body.layer3.4.bn1.running_mean\", \"backbone.body.layer3.4.bn1.running_var\", \"backbone.body.layer3.4.conv2.weight\", \"backbone.body.layer3.4.bn2.weight\", \"backbone.body.layer3.4.bn2.bias\", \"backbone.body.layer3.4.bn2.running_mean\", \"backbone.body.layer3.4.bn2.running_var\", \"backbone.body.layer3.4.conv3.weight\", \"backbone.body.layer3.4.bn3.weight\", \"backbone.body.layer3.4.bn3.bias\", \"backbone.body.layer3.4.bn3.running_mean\", \"backbone.body.layer3.4.bn3.running_var\", \"backbone.body.layer3.5.conv1.weight\", \"backbone.body.layer3.5.bn1.weight\", \"backbone.body.layer3.5.bn1.bias\", \"backbone.body.layer3.5.bn1.running_mean\", \"backbone.body.layer3.5.bn1.running_var\", \"backbone.body.layer3.5.conv2.weight\", \"backbone.body.layer3.5.bn2.weight\", \"backbone.body.layer3.5.bn2.bias\", \"backbone.body.layer3.5.bn2.running_mean\", \"backbone.body.layer3.5.bn2.running_var\", \"backbone.body.layer3.5.conv3.weight\", \"backbone.body.layer3.5.bn3.weight\", \"backbone.body.layer3.5.bn3.bias\", \"backbone.body.layer3.5.bn3.running_mean\", \"backbone.body.layer3.5.bn3.running_var\", \"backbone.body.layer4.0.conv1.weight\", \"backbone.body.layer4.0.bn1.weight\", \"backbone.body.layer4.0.bn1.bias\", \"backbone.body.layer4.0.bn1.running_mean\", \"backbone.body.layer4.0.bn1.running_var\", \"backbone.body.layer4.0.conv2.weight\", \"backbone.body.layer4.0.bn2.weight\", \"backbone.body.layer4.0.bn2.bias\", \"backbone.body.layer4.0.bn2.running_mean\", \"backbone.body.layer4.0.bn2.running_var\", \"backbone.body.layer4.0.conv3.weight\", \"backbone.body.layer4.0.bn3.weight\", \"backbone.body.layer4.0.bn3.bias\", \"backbone.body.layer4.0.bn3.running_mean\", \"backbone.body.layer4.0.bn3.running_var\", \"backbone.body.layer4.0.downsample.0.weight\", \"backbone.body.layer4.0.downsample.1.weight\", \"backbone.body.layer4.0.downsample.1.bias\", \"backbone.body.layer4.0.downsample.1.running_mean\", \"backbone.body.layer4.0.downsample.1.running_var\", \"backbone.body.layer4.1.conv1.weight\", \"backbone.body.layer4.1.bn1.weight\", \"backbone.body.layer4.1.bn1.bias\", \"backbone.body.layer4.1.bn1.running_mean\", \"backbone.body.layer4.1.bn1.running_var\", \"backbone.body.layer4.1.conv2.weight\", \"backbone.body.layer4.1.bn2.weight\", \"backbone.body.layer4.1.bn2.bias\", \"backbone.body.layer4.1.bn2.running_mean\", \"backbone.body.layer4.1.bn2.running_var\", \"backbone.body.layer4.1.conv3.weight\", \"backbone.body.layer4.1.bn3.weight\", \"backbone.body.layer4.1.bn3.bias\", \"backbone.body.layer4.1.bn3.running_mean\", \"backbone.body.layer4.1.bn3.running_var\", \"backbone.body.layer4.2.conv1.weight\", \"backbone.body.layer4.2.bn1.weight\", \"backbone.body.layer4.2.bn1.bias\", \"backbone.body.layer4.2.bn1.running_mean\", \"backbone.body.layer4.2.bn1.running_var\", \"backbone.body.layer4.2.conv2.weight\", \"backbone.body.layer4.2.bn2.weight\", \"backbone.body.layer4.2.bn2.bias\", \"backbone.body.layer4.2.bn2.running_mean\", \"backbone.body.layer4.2.bn2.running_var\", \"backbone.body.layer4.2.conv3.weight\", \"backbone.body.layer4.2.bn3.weight\", \"backbone.body.layer4.2.bn3.bias\", \"backbone.body.layer4.2.bn3.running_mean\", \"backbone.body.layer4.2.bn3.running_var\", \"backbone.fpn.inner_blocks.0.0.weight\", \"backbone.fpn.inner_blocks.0.0.bias\", \"backbone.fpn.inner_blocks.1.0.weight\", \"backbone.fpn.inner_blocks.1.0.bias\", \"backbone.fpn.inner_blocks.2.0.weight\", \"backbone.fpn.inner_blocks.2.0.bias\", \"backbone.fpn.inner_blocks.3.0.weight\", \"backbone.fpn.inner_blocks.3.0.bias\", \"backbone.fpn.layer_blocks.0.0.weight\", \"backbone.fpn.layer_blocks.0.0.bias\", \"backbone.fpn.layer_blocks.1.0.weight\", \"backbone.fpn.layer_blocks.1.0.bias\", \"backbone.fpn.layer_blocks.2.0.weight\", \"backbone.fpn.layer_blocks.2.0.bias\", \"backbone.fpn.layer_blocks.3.0.weight\", \"backbone.fpn.layer_blocks.3.0.bias\", \"rpn.head.conv.0.0.weight\", \"rpn.head.conv.0.0.bias\", \"rpn.head.cls_logits.weight\", \"rpn.head.cls_logits.bias\", \"rpn.head.bbox_pred.weight\", \"rpn.head.bbox_pred.bias\", \"roi_heads.box_head.fc6.weight\", \"roi_heads.box_head.fc6.bias\", \"roi_heads.box_head.fc7.weight\", \"roi_heads.box_head.fc7.bias\", \"roi_heads.box_predictor.cls_score.weight\", \"roi_heads.box_predictor.cls_score.bias\", \"roi_heads.box_predictor.bbox_pred.weight\", \"roi_heads.box_predictor.bbox_pred.bias\". \n",
            "\tUnexpected key(s) in state_dict: \"epoch\", \"model_state_dict\", \"optimizer_state_dict\", \"loss\". \n"
          ]
        }
      ]
    }
  ]
}