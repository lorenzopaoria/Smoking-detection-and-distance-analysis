{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-6xHSkVRra"
      },
      "source": [
        "Train a model for sigarette, smoker and non smoker detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSPrRYf-UiIR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import psutil\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIwrXGVosy",
        "outputId": "bc8bcc7a-831f-4dba-e593-233c9ea8cdc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9zfyZhMUziU"
      },
      "outputs": [],
      "source": [
        "class CigaretteDataset(Dataset):\n",
        "    def __init__(self, coco_annotation_file, image_dir, transform=None):\n",
        "        self.coco = COCO(coco_annotation_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform if transform is not None else transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        cat_ids = self.coco.getCatIds(catNms=['cigarette', 'smoker', 'nonSmoker'])\n",
        "        if not cat_ids:\n",
        "            raise ValueError(\"No 'cigarette' category found in COCO file.\")\n",
        "        self.image_ids = list(set(self.coco.getImgIds(catIds=cat_ids)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        image = Image.open(f\"{self.image_dir}/{img_info['file_name']}\").convert(\"RGB\")\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        annotations = self.coco.loadAnns(ann_ids)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        for ann in annotations:\n",
        "            cat_name = self.coco.loadCats(ann['category_id'])[0]['name']\n",
        "            x, y, w, h = ann['bbox']\n",
        "\n",
        "            if cat_name == 'cigarette':\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(1)\n",
        "            elif cat_name == 'smoker':\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(2)\n",
        "            elif cat_name == 'nonSmoker':\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(3)\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([img_id])\n",
        "        }\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQVR_UlEU6tP"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*[b for b in batch if b is not None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSTyDQ12U9e2"
      },
      "outputs": [],
      "source": [
        "def check_system_usage():\n",
        "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTd5J2NRaBEO"
      },
      "source": [
        "AP (Average Precision) a vari livelli di IoU,\n",
        "AR (Average Recall) per varie quantitÃ  di detections,\n",
        "mAP (mean Average Precision)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obrsp84GVAi1"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, device):\n",
        "    print(\"\\n=== Starting Validation ===\")\n",
        "    model.eval()\n",
        "    coco_dt = []\n",
        "    coco_gt = dataset.coco\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in tqdm(range(len(dataset)), desc=\"Validating\", ncols=100):\n",
        "            image, target = dataset[idx]\n",
        "            image = image.to(device)\n",
        "            prediction = model([image])\n",
        "\n",
        "            for box, score, label in zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']):\n",
        "                x, y, w, h = box.tolist()\n",
        "                coco_dt.append({\n",
        "                    'image_id': target['image_id'].item(),\n",
        "                    'category_id': label.item(),\n",
        "                    'bbox': [x, y, w-x, h-y],\n",
        "                    'score': score.item()\n",
        "                })\n",
        "\n",
        "    print(f\"\\nProcessed {len(coco_dt)} detections\")\n",
        "\n",
        "    if len(coco_dt) == 0:\n",
        "        print(\"No detections found during validation!\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        coco_dt = coco_gt.loadRes(coco_dt)\n",
        "        coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "\n",
        "        categories = dataset.coco.loadCats(dataset.coco.getCatIds())\n",
        "        for cat in categories:\n",
        "            coco_eval.params.catIds = [cat['id']]\n",
        "            coco_eval.evaluate()\n",
        "            coco_eval.accumulate()\n",
        "            print(f\"\\nResults for {cat['name']}:\")\n",
        "            coco_eval.summarize()\n",
        "\n",
        "        coco_eval.params.catIds = dataset.coco.getCatIds()\n",
        "        coco_eval.evaluate()\n",
        "        coco_eval.accumulate()\n",
        "        print(\"\\nOverall Results:\")\n",
        "        coco_eval.summarize()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during evaluation: {str(e)}\")\n",
        "\n",
        "    print(\"\\n=== Validation Complete ===\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9_EfpZLdFOI"
      },
      "outputs": [],
      "source": [
        "def train_model(dataset, num_epochs=10, val_dataset=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=4)\n",
        "    model = model.to(device)\n",
        "\n",
        "    data_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    scaler = torch.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "    epoch_losses = []\n",
        "    best_mAP = 0\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100, unit=\"batch\")):\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scaler is not None:\n",
        "                with torch.amp.autocast(device_type='cuda'):\n",
        "                    loss_dict = model(images, targets)\n",
        "                    loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss_dict = model(images, targets)\n",
        "                loss = sum(loss for loss in loss_dict.values())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "        check_system_usage()\n",
        "\n",
        "        if val_dataset:\n",
        "            print(\"\\nStarting validation...\")\n",
        "            coco_gt = val_dataset.coco\n",
        "            coco_dt = []\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for idx in tqdm(range(len(val_dataset)), desc=\"Validating\", ncols=100):\n",
        "                    try:\n",
        "                        image, target = val_dataset[idx]\n",
        "                        if image is None or target is None:\n",
        "                            continue\n",
        "\n",
        "                        image = image.to(device)\n",
        "                        prediction = model([image])\n",
        "\n",
        "                        # Filter predictions with confidence > 0.5\n",
        "                        boxes = prediction[0]['boxes'][prediction[0]['scores'] > 0.5]\n",
        "                        labels = prediction[0]['labels'][prediction[0]['scores'] > 0.5]\n",
        "                        scores = prediction[0]['scores'][prediction[0]['scores'] > 0.5]\n",
        "\n",
        "                        for box, score, label in zip(boxes, scores, labels):\n",
        "                            x, y, w, h = box.tolist()\n",
        "                            coco_dt.append({\n",
        "                                'image_id': target['image_id'].item(),\n",
        "                                'category_id': label.item(),\n",
        "                                'bbox': [x, y, w-x, h-y],\n",
        "                                'score': score.item()\n",
        "                            })\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing validation image {idx}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "            if len(coco_dt) > 0:\n",
        "                try:\n",
        "                    coco_dt = coco_gt.loadRes(coco_dt)\n",
        "                    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "                    coco_eval.evaluate()\n",
        "                    coco_eval.accumulate()\n",
        "                    coco_eval.summarize()\n",
        "\n",
        "                    # Get mAP@0.5 (index 1 in stats array)\n",
        "                    if coco_eval.stats is not None and len(coco_eval.stats) > 1:\n",
        "                        mAP = coco_eval.stats[1]\n",
        "                        print(f\"Epoch {epoch+1} mAP@0.5: {mAP:.4f}\")\n",
        "\n",
        "                        if mAP > best_mAP:\n",
        "                            best_mAP = mAP\n",
        "                            best_epoch = epoch + 1\n",
        "                            torch.save(model.state_dict(), 'best_model.pth')\n",
        "                            print(f\"New best model saved with mAP {best_mAP:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during evaluation: {str(e)}\")\n",
        "                    mAP = 0\n",
        "            else:\n",
        "                print(\"No valid detections in validation set\")\n",
        "                mAP = 0\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_loss,\n",
        "            'mAP': mAP if val_dataset else None\n",
        "        }\n",
        "        torch.save(checkpoint, f'model_epoch_{epoch+1}.pth')\n",
        "        print(f'Checkpoint saved: model_epoch_{epoch+1}.pth\\n')\n",
        "\n",
        "    if best_epoch > 0:\n",
        "        print(f\"Best model was from epoch {best_epoch} with mAP {best_mAP:.4f}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdj_-0BjVGDU",
        "outputId": "4b106e0b-5e10-4f45-e16e-5b906f1861bb"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_image_dir = '/content/drive/MyDrive/Photo/train'\n",
        "    train_coco_annotation_file = '/content/drive/MyDrive/Photo/train/_annotations.coco.json'\n",
        "\n",
        "    valid_image_dir = '/content/drive/MyDrive/Photo/valid'\n",
        "    valid_coco_annotation_file = '/content/drive/MyDrive/Photo/valid/_annotations.coco.json'\n",
        "\n",
        "    dataset = CigaretteDataset(train_coco_annotation_file, train_image_dir)\n",
        "    val_dataset = CigaretteDataset(valid_coco_annotation_file, valid_image_dir)\n",
        "\n",
        "    model = train_model(dataset, num_epochs=10, val_dataset= val_dataset)\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
