{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-6xHSkVRra"
      },
      "source": [
        "Train a model for sigarette detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MSPrRYf-UiIR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import psutil\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIwrXGVosy",
        "outputId": "f54c1156-3d69-4c1e-9281-08d2abd6f76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "B9zfyZhMUziU"
      },
      "outputs": [],
      "source": [
        "class CigaretteDataset(Dataset):\n",
        "    def __init__(self, coco_annotation_file, image_dir, transform=None):\n",
        "        self.coco = COCO(coco_annotation_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform if transform is not None else transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        cat_ids = self.coco.getCatIds(catNms=['cigarette'])\n",
        "        if not cat_ids:\n",
        "            raise ValueError(\"No 'cigarette' category found in COCO file.\")\n",
        "        self.image_ids = list(set(self.coco.getImgIds(catIds=cat_ids)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        image = Image.open(f\"{self.image_dir}/{img_info['file_name']}\").convert(\"RGB\")\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        annotations = self.coco.loadAnns(ann_ids)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        for ann in annotations:\n",
        "            if ann['category_id'] in self.coco.getCatIds(catNms=['cigarette']):\n",
        "                x, y, w, h = ann['bbox']\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(1)  # Class 1 for 'cigarette'\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        \n",
        "        image = self.transform(image)\n",
        "        \n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([img_id])\n",
        "        }\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tQVR_UlEU6tP"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*[b for b in batch if b is not None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jSTyDQ12U9e2"
      },
      "outputs": [],
      "source": [
        "def check_system_usage():\n",
        "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "obrsp84GVAi1"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, device):\n",
        "    model.eval()\n",
        "    coco_dt = []\n",
        "    coco_gt = dataset.coco\n",
        "    # Crea una lista di previsioni per ogni immagine nel dataset di validazione\n",
        "    for idx in range(len(dataset)):\n",
        "        image, target = dataset[idx]\n",
        "        image = image.to(device)\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image])\n",
        "        # Estrai le predizioni (boxes, labels, scores) e convertili nel formato COCO\n",
        "        for box, score, label in zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']):\n",
        "            coco_dt.append({\n",
        "                'image_id': target['image_id'].item(),\n",
        "                'category_id': label.item(),\n",
        "                'bbox': box.tolist(),\n",
        "                'score': score.item()\n",
        "            })\n",
        "\n",
        "    coco_dt = coco_gt.loadRes(coco_dt)  # Converti le predizioni in formato COCO\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "q9_EfpZLdFOI"
      },
      "outputs": [],
      "source": [
        "def train_model(dataset, num_epochs=10, val_dataset=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # Initialize model and move to device\n",
        "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    data_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    \n",
        "    # Use newer autocast and GradScaler API\n",
        "    scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100, unit=\"batch\")):\n",
        "            # Move images to device\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scaler is not None:\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    loss_dict = model(images, targets)\n",
        "                    loss = sum(loss for loss in loss_dict.values())\n",
        "                \n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss_dict = model(images, targets)\n",
        "                loss = sum(loss for loss in loss_dict.values())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "        check_system_usage()\n",
        "\n",
        "        if val_dataset:\n",
        "            evaluate_model(model, val_dataset, device)\n",
        "\n",
        "    torch.save(model.state_dict(), \"fasterrcnn_cigarette.pth\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdj_-0BjVGDU"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #psutil.Process().nice(psutil.BELOW_NORMAL_PRIORITY_CLASS)\n",
        "    train_image_dir = '/content/drive/MyDrive/Photo/train'\n",
        "    train_coco_annotation_file = '/content/drive/MyDrive/Photo/train/_annotations.coco.json'\n",
        "\n",
        "    valid_image_dir = '/content/drive/MyDrive/Photo/valid'\n",
        "    valid_coco_annotation_file = '/content/drive/MyDrive/Photo/valid/_annotations.coco.json'\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    dataset = CigaretteDataset(train_coco_annotation_file, train_image_dir)\n",
        "    val_dataset = CigaretteDataset(valid_coco_annotation_file, valid_image_dir)\n",
        "\n",
        "    model = train_model(dataset, num_epochs=20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
