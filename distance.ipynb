{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIJA1DQVax5A"
      },
      "source": [
        "Find the distance between smoker and not"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-python\n",
        "!git clone https://github.com/DepthAnything/Depth-Anything-V2.git\n",
        "%cd Depth-Anything-V2\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4xwcHdcZuvU",
        "outputId": "7c6fdcf7-fd3c-4d1f-c8e0-91596ec7bc4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Cloning into 'Depth-Anything-V2'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 142 (delta 45), reused 34 (delta 34), pack-reused 67 (from 2)\u001b[K\n",
            "Receiving objects: 100% (142/142), 45.17 MiB | 37.63 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/Depth-Anything-V2/Depth-Anything-V2/Depth-Anything-V2\n",
            "Requirement already satisfied: gradio_imageslider in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.0.20)\n",
            "Requirement already satisfied: gradio==4.29.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.29.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.11.0.86)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.20.1+cu124)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==0.16.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.16.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.9.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.16.1->gradio==4.29.0->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.16.1->gradio==4.29.0->-r requirements.txt (line 2)) (11.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (1.26.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r requirements.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==4.29.0->-r requirements.txt (line 2)) (0.45.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (0.22.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.29.0->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "90c--lc6ax5H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from depth_anything_v2.dpt import DepthAnythingV2\n",
        "import cv2\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "import math\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGhWYCnQax5K",
        "outputId": "6c96b769-3631-4a12-9e41-1adfc5b0ed8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# carica il modello Depth-Anything-V2\n",
        "depth_model = DepthAnythingV2()\n",
        "depth_model.load_state_dict(torch.load('/content/drive/MyDrive/pth_depth_estimation_large/depth_anything_v2_vitl.pth'))\n",
        "depth_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InF_QstFZ-3a",
        "outputId": "57d26368-a8ff-4587-b081-15d3bf50edd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-9a8e0d0f7c99>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  depth_model.load_state_dict(torch.load('/content/drive/MyDrive/pth_depth_estimation_large/depth_anything_v2_vitl.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DepthAnythingV2(\n",
              "  (pretrained): DinoVisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (blocks): ModuleList(\n",
              "      (0-23): 24 x NestedTensorBlock(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MemEffAttention(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "    (head): Identity()\n",
              "  )\n",
              "  (depth_head): DPTHead(\n",
              "    (projects): ModuleList(\n",
              "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2-3): 2 x Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (resize_layers): ModuleList(\n",
              "      (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (2): Identity()\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "    (scratch): Module(\n",
              "      (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (refinenet1): FeatureFusionBlock(\n",
              "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (resConfUnit1): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (resConfUnit2): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (refinenet2): FeatureFusionBlock(\n",
              "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (resConfUnit1): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (resConfUnit2): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (refinenet3): FeatureFusionBlock(\n",
              "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (resConfUnit1): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (resConfUnit2): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (refinenet4): FeatureFusionBlock(\n",
              "        (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (resConfUnit1): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (resConfUnit2): ResidualConvUnit(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (activation): ReLU()\n",
              "          (skip_add): FloatFunctional(\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "        )\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (output_conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (output_conv2): Sequential(\n",
              "        (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Person:\n",
        "    x1: int\n",
        "    y1: int\n",
        "    x2: int\n",
        "    y2: int\n",
        "    is_smoking: bool\n",
        "    confidence: float"
      ],
      "metadata": {
        "id": "vJYauE2pbOJu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_center_point(person: Person) -> Tuple[float, float]:\n",
        "    \"\"\"calcola il punto centrale di una bounding box\"\"\"\n",
        "    center_x = (person.x1 + person.x2) / 2\n",
        "    center_y = (person.y1 + person.y2) / 2\n",
        "    return (center_x, center_y)"
      ],
      "metadata": {
        "id": "VBPSx0lAatBb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m8ESvqphax5Q"
      },
      "outputs": [],
      "source": [
        "def calculate_depth_map(image):\n",
        "    \"\"\"genera una mappa di profondità per l'immagine utilizzando Depth-Anything-V2\"\"\"\n",
        "    image_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    with torch.no_grad():\n",
        "        depth_map = depth_model(image_tensor)\n",
        "    return depth_map.squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DZIUMc2Aax5R"
      },
      "outputs": [],
      "source": [
        "def calculate_3d_distance(p1: Person, p2: Person, depth_map, focal_length: float, image_width: float):\n",
        "    \"\"\"calcola la distanza 3D tra due persone utilizzando la mappa di profondità\"\"\"\n",
        "    c1 = calculate_center_point(p1)\n",
        "    c2 = calculate_center_point(p2)\n",
        "\n",
        "    # Ottieni la profondità media per ciascuna persona\n",
        "    depth1 = np.mean(depth_map[int(c1[1]):int(c2[1]), int(c1[0]):int(c2[0])])\n",
        "    depth2 = np.mean(depth_map[int(c2[1]):int(c2[1]), int(c2[0]):int(c2[0])])\n",
        "\n",
        "    # Calcola le coordinate 3D\n",
        "    x1 = (c1[0] - image_width / 2) * depth1 / focal_length\n",
        "    y1 = depth1\n",
        "    x2 = (c2[0] - image_width / 2) * depth2 / focal_length\n",
        "    y2 = depth2\n",
        "\n",
        "    # Distanza euclidea 3D\n",
        "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3J7n2BjYqUr9"
      },
      "outputs": [],
      "source": [
        "def find_smoker_nonsmoker_distances(people: List[Person], depth_map, focal_length: float, image_width: float) -> List[Tuple[Person, Person, float]]:\n",
        "    \"\"\"trova tutte le distanze 3D tra fumatori e non fumatori\"\"\"\n",
        "    smokers = [p for p in people if p.is_smoking]\n",
        "    non_smokers = [p for p in people if not p.is_smoking]\n",
        "    distances = []\n",
        "\n",
        "    for smoker in smokers:\n",
        "        for non_smoker in non_smokers:\n",
        "            distance = calculate_3d_distance(smoker, non_smoker, depth_map, focal_length, image_width)\n",
        "            distances.append((smoker, non_smoker, distance))\n",
        "\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_detections_from_json(json_path: str) -> List[Person]:\n",
        "    \"\"\"carica le detection dal file JSON e le converte in oggetti Person\"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    people = []\n",
        "    for detection in data['detections']:\n",
        "        # Classe 2 rappresenta il fumatore, 1 il non fumatore\n",
        "        is_smoking = detection['class'] == 2\n",
        "        is_not_smoking = detection['class'] == 1\n",
        "        bbox = detection['bbox']\n",
        "        people.append(Person(\n",
        "            x1=int(bbox[0]),\n",
        "            y1=int(bbox[1]),\n",
        "            x2=int(bbox[2]),\n",
        "            y2=int(bbox[3]),\n",
        "            is_smoking=is_smoking,\n",
        "            confidence=detection['confidence']\n",
        "        ))\n",
        "\n",
        "    return people"
      ],
      "metadata": {
        "id": "5MbsTMTLbfC0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3vfyIteXax5S"
      },
      "outputs": [],
      "source": [
        "def process_and_save_image(image_path: str, people: List[Person], output_dir: str, focal_length: float) -> None:\n",
        "    \"\"\"processa un'immagine disegnando le distanze 3D tra i centri delle bounding box\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Carica l'immagine\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Errore nel caricamento dell'immagine: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # Genera la mappa di profondità\n",
        "    depth_map = calculate_depth_map(image)\n",
        "\n",
        "    # Calcola le distanze 3D\n",
        "    distances = find_smoker_nonsmoker_distances(people, depth_map, focal_length, image.shape[1])\n",
        "\n",
        "    # Definizione colori\n",
        "    YELLOW = (0, 255, 255)  # BGR per giallo (centri)\n",
        "    BROWN = (42, 42, 165)   # BGR per marrone (linee distanza)\n",
        "    RED = (0, 0, 255)       # BGR per rosso (fumatori)\n",
        "    BLUE = (255, 0, 0)      # BGR per blu (non fumatori)\n",
        "\n",
        "    # Disegna le bounding box e i centri\n",
        "    for person in people:\n",
        "        color = RED if person.is_smoking else BLUE\n",
        "        cv2.rectangle(image, (int(person.x1), int(person.y1)), (int(person.x2), int(person.y2)), color, 2)\n",
        "        center = calculate_center_point(person)\n",
        "        cv2.circle(image, (int(center[0]), int(center[1])), 3, YELLOW, -1)\n",
        "\n",
        "    # Disegna le distanze\n",
        "    for smoker, non_smoker, distance in distances:\n",
        "        s_center = calculate_center_point(smoker)\n",
        "        ns_center = calculate_center_point(non_smoker)\n",
        "        cv2.line(image, (int(s_center[0]), int(s_center[1])), (int(ns_center[0]), int(ns_center[1])), BROWN, 2)\n",
        "        mid_point = ((s_center[0] + ns_center[0]) // 2, (s_center[1] + ns_center[1]) // 2)\n",
        "        cv2.putText(image, f\"{distance:.2f}m\", (int(mid_point[0]), int(mid_point[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.7, BROWN, 2)\n",
        "\n",
        "    output_path = os.path.join(output_dir, f\"distances_{os.path.basename(image_path)}\")\n",
        "    cv2.imwrite(output_path, image)\n",
        "    print(f\"Distanze 3D calcolate per {image_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haHiYRs6dLz-",
        "outputId": "d6f405ae-c553-4315-b747-1d69381b681e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore nel processare trained_40.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_41.jpg: Input image height 1151 is not a multiple of patch height 14\n",
            "Errore nel processare trained_42.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_43.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_44.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_45.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_46.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_47.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_48.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_49.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_50.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_51.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_52.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_53.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_54.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_55.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_56.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_57.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_58.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_59.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_60.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_61.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_62.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_63.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_64.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_65.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_66.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_67.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_68.jpg: Input image height 1152 is not a multiple of patch height 14\n",
            "Errore nel processare trained_69.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_70.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_71.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_72.jpg: Input image height 1153 is not a multiple of patch height 14\n",
            "Errore nel processare trained_73.jpg: Input image height 1153 is not a multiple of patch height 14\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    base_dir = '/content/drive/MyDrive/test_trained_person'\n",
        "    output_dir = '/content/drive/MyDrive/distance_img_process'\n",
        "    focal_length = 1000  # da calibrare in base alla videocamera\n",
        "\n",
        "    # Processa tutte le immagini nella cartella\n",
        "    images_dir = os.path.join(base_dir, 'images')\n",
        "    coordinates_dir = os.path.join(base_dir, 'coordinates')\n",
        "\n",
        "    for filename in os.listdir(images_dir):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            image_path = os.path.join(images_dir, filename)\n",
        "            json_name = f\"{os.path.splitext(filename)[0]}.json\"\n",
        "            json_path = os.path.join(coordinates_dir, json_name)\n",
        "\n",
        "            if os.path.exists(json_path):\n",
        "                try:\n",
        "                    people = load_detections_from_json(json_path)\n",
        "                    process_and_save_image(image_path, people, output_dir, focal_length)\n",
        "                    print(f\"Processata immagine: {filename}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Errore nel processare {filename}: {str(e)}\")\n",
        "            else:\n",
        "                print(f\"File JSON non trovato per {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}