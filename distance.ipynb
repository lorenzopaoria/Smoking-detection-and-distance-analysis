{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/distance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIJA1DQVax5A"
      },
      "source": [
        "Find the distance between smoker and not with help of depth model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4xwcHdcZuvU",
        "outputId": "4fbc4d5e-14bd-4b90-f0d0-afac5f2bf2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Cloning into 'Depth-Anything-V2'...\n",
            "remote: Enumerating objects: 142, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 142 (delta 45), reused 34 (delta 34), pack-reused 67 (from 2)\u001b[K\n",
            "Receiving objects: 100% (142/142), 45.17 MiB | 14.83 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n",
            "/content/Depth-Anything-V2/Depth-Anything-V2/Depth-Anything-V2\n",
            "Requirement already satisfied: gradio_imageslider in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.0.20)\n",
            "Requirement already satisfied: gradio==4.29.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.29.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.10.0.84)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.20.1+cu121)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==0.16.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.16.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.27.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.9.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==4.29.0->-r requirements.txt (line 2)) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.16.1->gradio==4.29.0->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==0.16.1->gradio==4.29.0->-r requirements.txt (line 2)) (11.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (4.55.6)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 5)) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (1.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.19.3->gradio==4.29.0->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0->-r requirements.txt (line 2)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==4.29.0->-r requirements.txt (line 2)) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==4.29.0->-r requirements.txt (line 2)) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi->gradio==4.29.0->-r requirements.txt (line 2)) (0.45.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (0.36.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.29.0->-r requirements.txt (line 2)) (0.22.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.24.1->gradio==4.29.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.19.3->gradio==4.29.0->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==4.29.0->-r requirements.txt (line 2)) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Installazione delle dipendenze\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-python\n",
        "!git clone https://github.com/DepthAnything/Depth-Anything-V2.git\n",
        "%cd Depth-Anything-V2\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "90c--lc6ax5H"
      },
      "outputs": [],
      "source": [
        "# Import delle librerie necessarie\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from depth_anything_v2.dpt import DepthAnythingV2\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "import math\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGhWYCnQax5K",
        "outputId": "5ebab48f-868d-4a97-abab-e1fea52acaa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "# Configurazione del dispositivo (GPU T4 su Colab)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Dispositivo in uso: {DEVICE}\")\n",
        "\n",
        "# Configurazione del modello DepthAnythingV2\n",
        "model_configs = {\n",
        "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
        "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
        "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
        "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
        "}\n",
        "\n",
        "encoder = 'vits'\n",
        "model = DepthAnythingV2(**model_configs[encoder])\n",
        "\n",
        "# Caricamento dei pesi del modello\n",
        "checkpoint_path = f'/content/drive/MyDrive/pth_depth_estimation_large/depth_anything_v2_{encoder}.pth'\n",
        "model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
        "model = model.to(DEVICE).eval()\n",
        "print(f\"Modello {encoder} caricato con successo su {DEVICE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLTVRQ6nXJPt",
        "outputId": "6dc5e79b-222e-4961-d691-e5c56ddf4b0c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dispositivo in uso: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-f763e90eb305>:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modello vits caricato con successo su cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vJYauE2pbOJu"
      },
      "outputs": [],
      "source": [
        "# Definizione della classe Person\n",
        "@dataclass\n",
        "class Person:\n",
        "    x1: int\n",
        "    y1: int\n",
        "    x2: int\n",
        "    y2: int\n",
        "    is_smoking: bool\n",
        "    confidence: float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1wpy_24bjOzH"
      },
      "outputs": [],
      "source": [
        "# Funzione per calcolare il punto centrale di una bounding box\n",
        "def calculate_center_point(person: Person) -> Tuple[float, float]:\n",
        "    \"\"\"Calcola il punto centrale di una bounding box\"\"\"\n",
        "    center_x = (person.x1 + person.x2) / 2\n",
        "    center_y = (person.y1 + person.y2) / 2\n",
        "    return (center_x, center_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mn-BQZSIjTXo"
      },
      "outputs": [],
      "source": [
        "# Funzione per ridimensionare l'immagine\n",
        "def resize_to_multiple_of_patch(image, patch_size=14, target_size=(512, 512)):\n",
        "    \"\"\"Ridimensiona l'immagine in modo che altezza e larghezza siano multipli di patch_size\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    new_h = math.ceil(h / patch_size) * patch_size\n",
        "    new_w = math.ceil(w / patch_size) * patch_size\n",
        "    # Ridimensiona l'immagine a una dimensione più piccola per risparmiare memoria\n",
        "    return cv2.resize(image, target_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VBPSx0lAatBb"
      },
      "outputs": [],
      "source": [
        "# Funzione per preprocessare l'immagine per il modello di profondità\n",
        "def preprocess_image_for_depth(image, target_size=(512, 512)):\n",
        "    \"\"\"Prepara l'immagine per il modello di profondità\"\"\"\n",
        "    resized_image = resize_to_multiple_of_patch(image, target_size=target_size)\n",
        "    image_tensor = torch.from_numpy(resized_image).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
        "    return resized_image, image_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "m8ESvqphax5Q"
      },
      "outputs": [],
      "source": [
        "# Funzione per calcolare la mappa di profondità\n",
        "def calculate_depth_map(image_tensor, model):\n",
        "    \"\"\"Genera una mappa di profondità utilizzando Depth-Anything-V2\"\"\"\n",
        "    with torch.no_grad():\n",
        "        depth_map = model(image_tensor.to(DEVICE))\n",
        "    return depth_map.squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DZIUMc2Aax5R"
      },
      "outputs": [],
      "source": [
        "# Funzione per scalare le bounding box\n",
        "def scale_bounding_boxes(people, original_image, resized_image):\n",
        "    \"\"\"Scala le coordinate delle bounding box in base al ridimensionamento dell'immagine\"\"\"\n",
        "    orig_h, orig_w = original_image.shape[:2]\n",
        "    new_h, new_w = resized_image.shape[:2]\n",
        "\n",
        "    scale_x = new_w / orig_w\n",
        "    scale_y = new_h / orig_h\n",
        "\n",
        "    scaled_people = []\n",
        "    for person in people:\n",
        "        scaled_person = Person(\n",
        "            x1=int(person.x1 * scale_x),\n",
        "            y1=int(person.y1 * scale_y),\n",
        "            x2=int(person.x2 * scale_x),\n",
        "            y2=int(person.y2 * scale_y),\n",
        "            is_smoking=person.is_smoking,\n",
        "            confidence=person.confidence\n",
        "        )\n",
        "        scaled_people.append(scaled_person)\n",
        "\n",
        "    return scaled_people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3J7n2BjYqUr9"
      },
      "outputs": [],
      "source": [
        "# Funzione per calcolare la distanza 3D\n",
        "def calculate_3d_distance(p1: Person, p2: Person, depth_map, focal_length: float, image_width: float):\n",
        "    \"\"\"Calcola la distanza 3D tra due persone utilizzando la mappa di profondità\"\"\"\n",
        "    c1 = calculate_center_point(p1)\n",
        "    c2 = calculate_center_point(p2)\n",
        "\n",
        "    c1_x, c1_y = max(0, min(int(c1[0]), depth_map.shape[1]-1)), max(0, min(int(c1[1]), depth_map.shape[0]-1))\n",
        "    c2_x, c2_y = max(0, min(int(c2[0]), depth_map.shape[1]-1)), max(0, min(int(c2[1]), depth_map.shape[0]-1))\n",
        "\n",
        "    radius = 5\n",
        "    p1_area = depth_map[max(0, c1_y-radius):min(depth_map.shape[0], c1_y+radius),\n",
        "                        max(0, c1_x-radius):min(depth_map.shape[1], c1_x+radius)]\n",
        "    p2_area = depth_map[max(0, c2_y-radius):min(depth_map.shape[0], c2_y+radius),\n",
        "                        max(0, c2_x-radius):min(depth_map.shape[1], c2_x+radius)]\n",
        "\n",
        "    depth1 = np.median(p1_area) if p1_area.size > 0 else depth_map[c1_y, c1_x]\n",
        "    depth2 = np.median(p2_area) if p2_area.size > 0 else depth_map[c2_y, c2_x]\n",
        "\n",
        "    x1 = (c1_x - image_width / 2) * depth1 / focal_length\n",
        "    y1 = depth1\n",
        "    x2 = (c2_x - image_width / 2) * depth2 / focal_length\n",
        "    y2 = depth2\n",
        "\n",
        "    distance = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
        "    scale_factor = 0.1\n",
        "    distance_meters = distance * scale_factor\n",
        "\n",
        "    return distance_meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5MbsTMTLbfC0"
      },
      "outputs": [],
      "source": [
        "# Funzione per trovare le distanze tra fumatori e non fumatori\n",
        "def find_smoker_nonsmoker_distances(people: List[Person], depth_map, focal_length: float, image_width: float) -> List[Tuple[Person, Person, float]]:\n",
        "    \"\"\"Trova tutte le distanze 3D tra fumatori e non fumatori\"\"\"\n",
        "    smokers = [p for p in people if p.is_smoking]\n",
        "    non_smokers = [p for p in people if not p.is_smoking]\n",
        "    distances = []\n",
        "\n",
        "    for smoker in smokers:\n",
        "        for non_smoker in non_smokers:\n",
        "            distance = calculate_3d_distance(smoker, non_smoker, depth_map, focal_length, image_width)\n",
        "            distances.append((smoker, non_smoker, distance))\n",
        "\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vjzlPWVxkLUs"
      },
      "outputs": [],
      "source": [
        "# Funzione per caricare le detection da un file JSON\n",
        "def load_detections_from_json(json_path: str) -> List[Person]:\n",
        "    \"\"\"Carica le detection dal file JSON e le converte in oggetti Person\"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    people = []\n",
        "    if 'detections' in data:\n",
        "        for detection in data['detections']:\n",
        "            is_smoking = detection.get('class') == 2\n",
        "            bbox = detection.get('bbox', [0, 0, 0, 0])\n",
        "            confidence = detection.get('confidence', 0.0)\n",
        "\n",
        "            if len(bbox) == 4:\n",
        "                people.append(Person(\n",
        "                    x1=int(bbox[0]),\n",
        "                    y1=int(bbox[1]),\n",
        "                    x2=int(bbox[2]),\n",
        "                    y2=int(bbox[3]),\n",
        "                    is_smoking=is_smoking,\n",
        "                    confidence=confidence\n",
        "                ))\n",
        "\n",
        "    return people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3vfyIteXax5S"
      },
      "outputs": [],
      "source": [
        "# Funzione per processare e salvare l'immagine\n",
        "def process_and_save_image(image_path: str, people: List[Person], output_dir: str, focal_length: float, model) -> bool:\n",
        "    \"\"\"Processa un'immagine disegnando le distanze 3D tra i centri delle bounding box\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    original_image = cv2.imread(image_path)\n",
        "    if original_image is None:\n",
        "        print(f\"Errore nel caricamento dell'immagine: {image_path}\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Libera la memoria della GPU prima di elaborare l'immagine\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        resized_image, image_tensor = preprocess_image_for_depth(original_image)\n",
        "        scaled_people = scale_bounding_boxes(people, original_image, resized_image)\n",
        "        depth_map = calculate_depth_map(image_tensor, model)\n",
        "        depth_display = cv2.resize(depth_map, (original_image.shape[1], original_image.shape[0]))\n",
        "        normalized_depth = cv2.normalize(depth_display, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "        colored_depth = cv2.applyColorMap(normalized_depth, cv2.COLORMAP_INFERNO)\n",
        "\n",
        "        distances = find_smoker_nonsmoker_distances(scaled_people, depth_map, focal_length, resized_image.shape[1])\n",
        "\n",
        "        visualized_image = resized_image.copy()\n",
        "\n",
        "        YELLOW = (0, 255, 255)\n",
        "        BROWN = (42, 42, 165)\n",
        "        RED = (0, 0, 255)\n",
        "        BLUE = (255, 0, 0)\n",
        "        GREEN = (0, 255, 0)\n",
        "\n",
        "        for person in scaled_people:\n",
        "            color = RED if person.is_smoking else BLUE\n",
        "            cv2.rectangle(visualized_image, (int(person.x1), int(person.y1)),\n",
        "                         (int(person.x2), int(person.y2)), color, 2)\n",
        "            center = calculate_center_point(person)\n",
        "            cv2.circle(visualized_image, (int(center[0]), int(center[1])), 5, YELLOW, -1)\n",
        "\n",
        "            label = \"Smoker\" if person.is_smoking else \"Non-smoker\"\n",
        "            conf_text = f\"{person.confidence:.2f}\"\n",
        "            cv2.putText(visualized_image, f\"{label} {conf_text}\",\n",
        "                       (int(person.x1), int(person.y1) - 10),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        for smoker, non_smoker, distance in distances:\n",
        "            s_center = calculate_center_point(smoker)\n",
        "            ns_center = calculate_center_point(non_smoker)\n",
        "\n",
        "            cv2.line(visualized_image,\n",
        "                    (int(s_center[0]), int(s_center[1])),\n",
        "                    (int(ns_center[0]), int(ns_center[1])),\n",
        "                    BROWN, 2)\n",
        "\n",
        "            mid_point = ((s_center[0] + ns_center[0]) // 2, (s_center[1] + ns_center[1]) // 2)\n",
        "\n",
        "            text = f\"{distance:.2f}m\"\n",
        "            (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
        "            cv2.rectangle(visualized_image,\n",
        "                         (int(mid_point[0] - text_w/2 - 5), int(mid_point[1] - text_h - 5)),\n",
        "                         (int(mid_point[0] + text_w/2 + 5), int(mid_point[1] + 5)),\n",
        "                         (255, 255, 255), -1)\n",
        "\n",
        "            cv2.putText(visualized_image, text,\n",
        "                       (int(mid_point[0] - text_w/2), int(mid_point[1])),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, GREEN, 2)\n",
        "\n",
        "        filename = os.path.basename(image_path)\n",
        "        output_path = os.path.join(output_dir, f\"distances_{filename}\")\n",
        "        cv2.imwrite(output_path, visualized_image)\n",
        "\n",
        "        depth_output_path = os.path.join(output_dir, f\"depth_{filename}\")\n",
        "        cv2.imwrite(depth_output_path, colored_depth)\n",
        "\n",
        "        h, w = original_image.shape[:2]\n",
        "        resized_original = cv2.resize(original_image, (w, h))\n",
        "        resized_depth = cv2.resize(colored_depth, (w, h))\n",
        "        resized_visualization = cv2.resize(visualized_image, (w, h))\n",
        "\n",
        "        composite = np.hstack((resized_original, resized_depth, resized_visualization))\n",
        "        composite_output_path = os.path.join(output_dir, f\"composite_{filename}\")\n",
        "        cv2.imwrite(composite_output_path, composite)\n",
        "\n",
        "        print(f\"Elaborazione completata per {image_path}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante l'elaborazione di {image_path}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haHiYRs6dLz-",
        "outputId": "6a8c9da9-2e49-4bfa-f676-90f130be1f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elaborazione delle immagini in /content/drive/MyDrive/test_trained_person/images...\n",
            "Trovate 34 immagini da elaborare.\n",
            "[1/34] Elaborazione di trained_40.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_40.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_40.jpg\n",
            "[2/34] Elaborazione di trained_41.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_41.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_41.jpg\n",
            "[3/34] Elaborazione di trained_42.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_42.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_42.jpg\n",
            "[4/34] Elaborazione di trained_43.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_43.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_43.jpg\n",
            "[5/34] Elaborazione di trained_44.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_44.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_44.jpg\n",
            "[6/34] Elaborazione di trained_45.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_45.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_45.jpg\n",
            "[7/34] Elaborazione di trained_46.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_46.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_46.jpg\n",
            "[8/34] Elaborazione di trained_47.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_47.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_47.jpg\n",
            "[9/34] Elaborazione di trained_48.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_48.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_48.jpg\n",
            "[10/34] Elaborazione di trained_49.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_49.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_49.jpg\n",
            "[11/34] Elaborazione di trained_50.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_50.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_50.jpg\n",
            "[12/34] Elaborazione di trained_51.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_51.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_51.jpg\n",
            "[13/34] Elaborazione di trained_52.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_52.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_52.jpg\n",
            "[14/34] Elaborazione di trained_53.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_53.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_53.jpg\n",
            "[15/34] Elaborazione di trained_54.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_54.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_54.jpg\n",
            "[16/34] Elaborazione di trained_55.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_55.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_55.jpg\n",
            "[17/34] Elaborazione di trained_56.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_56.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_56.jpg\n",
            "[18/34] Elaborazione di trained_57.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_57.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_57.jpg\n",
            "[19/34] Elaborazione di trained_58.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_58.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_58.jpg\n",
            "[20/34] Elaborazione di trained_59.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_59.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_59.jpg\n",
            "[21/34] Elaborazione di trained_60.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_60.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_60.jpg\n",
            "[22/34] Elaborazione di trained_61.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_61.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_61.jpg\n",
            "[23/34] Elaborazione di trained_62.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_62.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_62.jpg\n",
            "[24/34] Elaborazione di trained_63.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_63.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_63.jpg\n",
            "[25/34] Elaborazione di trained_64.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_64.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_64.jpg\n",
            "[26/34] Elaborazione di trained_65.jpg...\n",
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_65.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_65.jpg\n",
            "[27/34] Elaborazione di trained_66.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_66.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_66.jpg\n",
            "[28/34] Elaborazione di trained_67.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_67.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_67.jpg\n",
            "[29/34] Elaborazione di trained_68.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_68.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_68.jpg\n",
            "[30/34] Elaborazione di trained_69.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_69.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_69.jpg\n",
            "[31/34] Elaborazione di trained_70.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_70.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_70.jpg\n",
            "[32/34] Elaborazione di trained_71.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_71.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_71.jpg\n",
            "[33/34] Elaborazione di trained_72.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_72.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_72.jpg\n",
            "[34/34] Elaborazione di trained_73.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Errore durante l'elaborazione di /content/drive/MyDrive/test_trained_person/images/trained_73.jpg: Input image height 512 is not a multiple of patch height 14\n",
            "Errore nell'elaborazione dell'immagine trained_73.jpg\n",
            "\n",
            "=== RIEPILOGO DELL'ELABORAZIONE ===\n",
            "Immagini elaborate con successo: 0\n",
            "Immagini non elaborate (errori): 34\n",
            "Immagini saltate (file mancanti o nessuna persona): 0\n",
            "Totale immagini processate: 34 di 34\n",
            "Risultati salvati in: /content/drive/MyDrive/distance_img_process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-c606a8f0237a>\", line 17, in process_and_save_image\n",
            "    depth_map = calculate_depth_map(image_tensor, model)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-27-f7e44315a4a4>\", line 5, in calculate_depth_map\n",
            "    depth_map = model(image_tensor.to(DEVICE))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dpt.py\", line 179, in forward\n",
            "    features = self.pretrained.get_intermediate_layers(x, self.intermediate_layer_idx[self.encoder], return_class_token=True)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 308, in get_intermediate_layers\n",
            "    outputs = self._get_intermediate_layers_not_chunked(x, n)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 272, in _get_intermediate_layers_not_chunked\n",
            "    x = self.prepare_tokens_with_masks(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2.py\", line 214, in prepare_tokens_with_masks\n",
            "    x = self.patch_embed(x)\n",
            "        ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Depth-Anything-V2/depth_anything_v2/dinov2_layers/patch_embed.py\", line 73, in forward\n",
            "    assert H % patch_H == 0, f\"Input image height {H} is not a multiple of patch height {patch_H}\"\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "AssertionError: Input image height 512 is not a multiple of patch height 14\n"
          ]
        }
      ],
      "source": [
        "# Funzione principale\n",
        "def main():\n",
        "    base_dir = '/content/drive/MyDrive/test_trained_person'\n",
        "    output_dir = '/content/drive/MyDrive/distance_img_process'\n",
        "    focal_length = 1000  # Parametro da calibrare in base al focale della camera\n",
        "\n",
        "    images_dir = os.path.join(base_dir, 'images')\n",
        "    coordinates_dir = os.path.join(base_dir, 'coordinates')\n",
        "\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "    skipped = 0\n",
        "\n",
        "    print(f\"Elaborazione delle immagini in {images_dir}...\")\n",
        "\n",
        "    if not os.path.exists(images_dir):\n",
        "        print(f\"La directory delle immagini {images_dir} non esiste!\")\n",
        "        return\n",
        "    if not os.path.exists(coordinates_dir):\n",
        "        print(f\"La directory delle coordinate {coordinates_dir} non esiste!\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"Trovate {len(image_files)} immagini da elaborare.\")\n",
        "\n",
        "    for i, filename in enumerate(image_files):\n",
        "        print(f\"[{i+1}/{len(image_files)}] Elaborazione di {filename}...\")\n",
        "\n",
        "        image_path = os.path.join(images_dir, filename)\n",
        "        json_name = f\"{os.path.splitext(filename)[0]}.json\"\n",
        "        json_path = os.path.join(coordinates_dir, json_name)\n",
        "\n",
        "        if not os.path.exists(json_path):\n",
        "            print(f\"File JSON non trovato per {filename}, saltato.\")\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            people = load_detections_from_json(json_path)\n",
        "            if not people:\n",
        "                print(f\"Nessuna persona rilevata in {filename}, saltato.\")\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            success = process_and_save_image(image_path, people, output_dir, focal_length, model)\n",
        "            if success:\n",
        "                successful += 1\n",
        "                print(f\"✅ Immagine {filename} elaborata con successo\")\n",
        "            else:\n",
        "                failed += 1\n",
        "                print(f\"Errore nell'elaborazione dell'immagine {filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Errore catastrofico nell'elaborazione di {filename}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            failed += 1\n",
        "\n",
        "    print(f\"\\n=== RIEPILOGO DELL'ELABORAZIONE ===\")\n",
        "    print(f\"Immagini elaborate con successo: {successful}\")\n",
        "    print(f\"Immagini non elaborate (errori): {failed}\")\n",
        "    print(f\"Immagini saltate (file mancanti o nessuna persona): {skipped}\")\n",
        "    print(f\"Totale immagini processate: {successful + failed} di {len(image_files)}\")\n",
        "    print(f\"Risultati salvati in: {output_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import traceback\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"Errore nell'esecuzione del programma: {str(e)}\")\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}