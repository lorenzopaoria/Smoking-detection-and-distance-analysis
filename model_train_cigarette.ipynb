{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model_train_cigarette.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-6xHSkVRra"
      },
      "source": [
        "Train a model for sigarette detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MSPrRYf-UiIR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import psutil\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F, Compose, Resize, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIwrXGVosy",
        "outputId": "0a787c4b-653b-43d1-d5bb-b68eb41b6055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMipeipr9n0T"
      },
      "outputs": [],
      "source": [
        "class CigaretteDataset(Dataset):\n",
        "    def __init__(self, coco_annotation_file, image_dir, transform=None):\n",
        "        self.coco = COCO(coco_annotation_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        cat_ids = self.coco.getCatIds(catNms=['cigarette'])\n",
        "        if not cat_ids:\n",
        "            raise ValueError(\"Nessuna categoria 'cigarette' trovata nel file COCO.\")\n",
        "        self.image_ids = list(set(self.coco.getImgIds(catIds=cat_ids)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        image = Image.open(f\"{self.image_dir}/{img_info['file_name']}\").convert(\"RGB\")\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        annotations = self.coco.loadAnns(ann_ids)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        for ann in annotations:\n",
        "            if ann['category_id'] in self.coco.getCatIds(catNms=['cigarette']):\n",
        "                x, y, w, h = ann['bbox']\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(1)  # Classe 1 per 'cigarette'\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([img_id])}\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zCmmBmSg9n0U"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*[b for b in batch if b is not None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-W4OPACV9n0V"
      },
      "outputs": [],
      "source": [
        "def check_system_usage():\n",
        "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ny3cwv1_9n0V"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, val_dataset, device):\n",
        "    model.eval()\n",
        "    coco_gt = val_dataset.coco\n",
        "    coco_dt = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in tqdm(range(len(val_dataset)), desc=\"Evaluating Model\"):\n",
        "            image, target = val_dataset[idx]\n",
        "            if not isinstance(image, torch.Tensor):\n",
        "                image = transforms.ToTensor()(image)\n",
        "\n",
        "            image = image.to(device)\n",
        "            prediction = model([image])\n",
        "\n",
        "            for box, score, label in zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']):\n",
        "                x, y, w, h = box[0].item(), box[1].item(), (box[2] - box[0]).item(), (box[3] - box[1]).item()\n",
        "                coco_dt.append({\n",
        "                    'image_id': target['image_id'].item(),\n",
        "                    'category_id': label.item(),\n",
        "                    'bbox': [x, y, w, h],\n",
        "                    'score': score.item()\n",
        "                })\n",
        "\n",
        "    if not coco_dt:\n",
        "        return 0.0\n",
        "\n",
        "    coco_pred = coco_gt.loadRes(coco_dt)\n",
        "    cocoEval = COCOeval(coco_gt, coco_pred, 'bbox')\n",
        "    cocoEval.evaluate()\n",
        "    cocoEval.accumulate()\n",
        "    cocoEval.summarize()\n",
        "\n",
        "    return cocoEval.stats[0]  # Returns mAP@0.5:0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RAM--JDL-2EK"
      },
      "outputs": [],
      "source": [
        "def train_model(dataset, num_epochs=10, val_dataset=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)\n",
        "    model.to(device)\n",
        "\n",
        "    # Create save directory if it doesn't exist\n",
        "    save_dir = '/content/drive/MyDrive/pth_cigarette_detect'\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    scaler = torch.amp.GradScaler()\n",
        "\n",
        "    # Early stopping parameters\n",
        "    best_map = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "    best_epoch = 0\n",
        "\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)):\n",
        "            images = [transforms.ToTensor()(img).to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                loss_dict = model(images, targets)\n",
        "                loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "        check_system_usage()\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        if val_dataset:\n",
        "            current_map = evaluate_model(model, val_dataset, device)\n",
        "            print(f\"Current mAP: {current_map:.4f}\")\n",
        "\n",
        "            # Save the last model\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': avg_loss,\n",
        "                'map': current_map\n",
        "            }, f\"{save_dir}/last_model.pth\")\n",
        "\n",
        "            # Check if this is the best model\n",
        "            if current_map > best_map:\n",
        "                best_map = current_map\n",
        "                best_epoch = epoch\n",
        "                epochs_without_improvement = 0\n",
        "\n",
        "                # Save the best model\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': avg_loss,\n",
        "                    'map': current_map\n",
        "                }, f\"{save_dir}/best_model.pth\")\n",
        "\n",
        "                print(f\"New best model saved! mAP: {current_map:.4f}\")\n",
        "            else:\n",
        "                epochs_without_improvement += 1\n",
        "                print(f\"Epochs without improvement: {epochs_without_improvement}\")\n",
        "\n",
        "            # Early stopping conditions\n",
        "            if epoch >= 10:  # Minimum number of epochs\n",
        "                if epochs_without_improvement >= 6:  # No improvement for 6 epochs\n",
        "                    if current_map < (best_map + 0.006):  # No improvement of 0.6%\n",
        "                        print(f\"Early stopping triggered! Best mAP: {best_map:.4f} at epoch {best_epoch+1}\")\n",
        "                        break\n",
        "\n",
        "    print(f\"Training completed. Best mAP: {best_map:.4f} at epoch {best_epoch+1}\")\n",
        "    return model, best_map, epoch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTKPIfSe9n0W",
        "outputId": "ba0f5ea1-0712-46a2-8893-06125e10bde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.22s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Inizio Epoca 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 1/10: 100%|████████████████████████████████████████████████| 92/92 [04:13<00:00,  2.75s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1/10, Loss: 0.3558, Tempo: 253.45s\n",
            "CPU Usage: 73.6%\n",
            "RAM Usage: 26.1%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 2/10: 100%|████████████████████████████████████████████████| 92/92 [04:10<00:00,  2.72s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 2/10, Loss: 0.2175, Tempo: 250.37s\n",
            "CPU Usage: 72.7%\n",
            "RAM Usage: 27.3%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 3/10: 100%|████████████████████████████████████████████████| 92/92 [04:14<00:00,  2.77s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 3/10, Loss: 0.1827, Tempo: 254.76s\n",
            "CPU Usage: 72.7%\n",
            "RAM Usage: 27.5%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 4/10: 100%|████████████████████████████████████████████████| 92/92 [04:11<00:00,  2.74s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 4/10, Loss: 0.1575, Tempo: 252.00s\n",
            "CPU Usage: 73.1%\n",
            "RAM Usage: 27.5%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 5/10: 100%|████████████████████████████████████████████████| 92/92 [04:13<00:00,  2.75s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 5/10, Loss: 0.1344, Tempo: 253.11s\n",
            "CPU Usage: 72.9%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 6/10: 100%|████████████████████████████████████████████████| 92/92 [04:12<00:00,  2.74s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 6/10, Loss: 0.1250, Tempo: 252.08s\n",
            "CPU Usage: 72.3%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 7/10: 100%|████████████████████████████████████████████████| 92/92 [04:14<00:00,  2.76s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 7/10, Loss: 0.1122, Tempo: 254.06s\n",
            "CPU Usage: 72.6%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 8/10: 100%|████████████████████████████████████████████████| 92/92 [04:14<00:00,  2.77s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 8/10, Loss: 0.1002, Tempo: 254.86s\n",
            "CPU Usage: 72.3%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 9/10: 100%|████████████████████████████████████████████████| 92/92 [04:09<00:00,  2.72s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 9/10, Loss: 0.0970, Tempo: 249.92s\n",
            "CPU Usage: 72.7%\n",
            "RAM Usage: 27.3%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 10/10: 100%|███████████████████████████████████████████████| 92/92 [04:10<00:00,  2.72s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 10/10, Loss: 0.0883, Tempo: 250.09s\n",
            "CPU Usage: 73.2%\n",
            "RAM Usage: 27.1%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.36it/s]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_image_dir = '/content/drive/MyDrive/Photo/train'\n",
        "    train_coco_annotation_file = '/content/drive/MyDrive/Photo/train/_annotations.coco.json'\n",
        "\n",
        "    valid_image_dir = '/content/drive/MyDrive/Photo/valid'\n",
        "    valid_coco_annotation_file = '/content/drive/MyDrive/Photo/valid/_annotations.coco.json'\n",
        "\n",
        "    dataset = CigaretteDataset(train_coco_annotation_file, train_image_dir)\n",
        "    val_dataset = CigaretteDataset(valid_coco_annotation_file, valid_image_dir)\n",
        "\n",
        "    model = train_model(dataset, num_epochs=30, val_dataset= val_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}