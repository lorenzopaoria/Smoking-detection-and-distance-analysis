{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model_train_cigarette.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-6xHSkVRra"
      },
      "source": [
        "Train a model for sigarette detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MSPrRYf-UiIR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import psutil\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F, Compose, Resize, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIwrXGVosy",
        "outputId": "0a787c4b-653b-43d1-d5bb-b68eb41b6055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMipeipr9n0T"
      },
      "outputs": [],
      "source": [
        "class CigaretteDataset(Dataset):\n",
        "    def __init__(self, coco_annotation_file, image_dir, transform=None):\n",
        "        self.coco = COCO(coco_annotation_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        cat_ids = self.coco.getCatIds(catNms=['cigarette'])\n",
        "        if not cat_ids:\n",
        "            raise ValueError(\"Nessuna categoria 'cigarette' trovata nel file COCO.\")\n",
        "        self.image_ids = list(set(self.coco.getImgIds(catIds=cat_ids)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        image = Image.open(f\"{self.image_dir}/{img_info['file_name']}\").convert(\"RGB\")\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        annotations = self.coco.loadAnns(ann_ids)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        for ann in annotations:\n",
        "            if ann['category_id'] in self.coco.getCatIds(catNms=['cigarette']):\n",
        "                x, y, w, h = ann['bbox']\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(1)  # Classe 1 per 'cigarette'\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "        target = {'boxes': boxes, 'labels': labels, 'image_id': torch.tensor([img_id])}\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zCmmBmSg9n0U"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*[b for b in batch if b is not None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-W4OPACV9n0V"
      },
      "outputs": [],
      "source": [
        "def check_system_usage():\n",
        "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ny3cwv1_9n0V"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    coco_dt = []  # Initialize here\n",
        "\n",
        "    for idx in tqdm(range(len(dataset)), desc=\"Evaluating Model\"):\n",
        "        image, target = dataset[idx]\n",
        "\n",
        "        if not isinstance(image, torch.Tensor):  # Convert if still a PIL image\n",
        "            image = transforms.ToTensor()(image)\n",
        "\n",
        "        image = image.to(device)  # Move input to the same device as the model\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image])\n",
        "\n",
        "        # Extract predictions (boxes, labels, scores) and convert them into COCO format\n",
        "        for box, score, label in zip(prediction[0]['boxes'], prediction[0]['scores'], prediction[0]['labels']):\n",
        "            coco_dt.append({\n",
        "                'image_id': target['image_id'].item(),\n",
        "                'category_id': label.item(),\n",
        "                'bbox': box.tolist(),\n",
        "                'score': score.item()\n",
        "            })\n",
        "\n",
        "    return coco_dt  # Make sure to return the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RAM--JDL-2EK"
      },
      "outputs": [],
      "source": [
        "def train_model(dataset, num_epochs=10, val_dataset=None):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=2)\n",
        "    model.to(device)\n",
        "\n",
        "    data_loader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    epoch_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        print(f\"Inizio Epoca {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        # Usa tqdm per aggiungere la progress bar\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f\"Epoca {epoch+1}/{num_epochs}\", ncols=100, unit=\"batch\")):\n",
        "            images = [transforms.ToTensor()(img).to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)\n",
        "\n",
        "        print(f\"Epoca {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Tempo: {time.time() - start_time:.2f}s\")\n",
        "        check_system_usage()\n",
        "\n",
        "        # Valutazione del modello su dataset di validazione\n",
        "        if val_dataset:\n",
        "            evaluate_model(model, val_dataset, device)\n",
        "\n",
        "    torch.save(model.state_dict(), \"fasterrcnn_cigarette.pth\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTKPIfSe9n0W",
        "outputId": "ba0f5ea1-0712-46a2-8893-06125e10bde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.22s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Inizio Epoca 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 1/10: 100%|████████████████████████████████████████████████| 92/92 [04:13<00:00,  2.75s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1/10, Loss: 0.3558, Tempo: 253.45s\n",
            "CPU Usage: 73.6%\n",
            "RAM Usage: 26.1%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.37 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 2/10: 100%|████████████████████████████████████████████████| 92/92 [04:10<00:00,  2.72s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 2/10, Loss: 0.2175, Tempo: 250.37s\n",
            "CPU Usage: 72.7%\n",
            "RAM Usage: 27.3%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 3/10: 100%|████████████████████████████████████████████████| 92/92 [04:14<00:00,  2.77s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 3/10, Loss: 0.1827, Tempo: 254.76s\n",
            "CPU Usage: 72.7%\n",
            "RAM Usage: 27.5%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 4/10: 100%|████████████████████████████████████████████████| 92/92 [04:11<00:00,  2.74s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 4/10, Loss: 0.1575, Tempo: 252.00s\n",
            "CPU Usage: 73.1%\n",
            "RAM Usage: 27.5%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 5/10: 100%|████████████████████████████████████████████████| 92/92 [04:13<00:00,  2.75s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 5/10, Loss: 0.1344, Tempo: 253.11s\n",
            "CPU Usage: 72.9%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 6/10: 100%|████████████████████████████████████████████████| 92/92 [04:12<00:00,  2.74s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 6/10, Loss: 0.1250, Tempo: 252.08s\n",
            "CPU Usage: 72.3%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 7/10: 100%|████████████████████████████████████████████████| 92/92 [04:14<00:00,  2.76s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 7/10, Loss: 0.1122, Tempo: 254.06s\n",
            "CPU Usage: 72.6%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 8/10: 100%|████████████████████████████████████████████████| 92/92 [04:14<00:00,  2.77s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 8/10, Loss: 0.1002, Tempo: 254.86s\n",
            "CPU Usage: 72.3%\n",
            "RAM Usage: 27.4%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 9/10: 100%|████████████████████████████████████████████████| 92/92 [04:09<00:00,  2.72s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 9/10, Loss: 0.0970, Tempo: 249.92s\n",
            "CPU Usage: 72.7%\n",
            "RAM Usage: 27.3%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inizio Epoca 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoca 10/10: 100%|███████████████████████████████████████████████| 92/92 [04:10<00:00,  2.72s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 10/10, Loss: 0.0883, Tempo: 250.09s\n",
            "CPU Usage: 73.2%\n",
            "RAM Usage: 27.1%\n",
            "GPU Memory Allocated: 0.80 GB\n",
            "GPU Memory Reserved: 12.38 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Model: 100%|██████████| 142/142 [00:26<00:00,  5.36it/s]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_image_dir = '/content/drive/MyDrive/Photo/train'\n",
        "    train_coco_annotation_file = '/content/drive/MyDrive/Photo/train/_annotations.coco.json'\n",
        "\n",
        "    valid_image_dir = '/content/drive/MyDrive/Photo/valid'\n",
        "    valid_coco_annotation_file = '/content/drive/MyDrive/Photo/valid/_annotations.coco.json'\n",
        "\n",
        "    dataset = CigaretteDataset(train_coco_annotation_file, train_image_dir)\n",
        "    val_dataset = CigaretteDataset(valid_coco_annotation_file, valid_image_dir)\n",
        "\n",
        "    model = train_model(dataset, num_epochs=10, val_dataset= val_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}