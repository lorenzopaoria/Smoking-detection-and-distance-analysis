{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model_train_cigarette.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-6xHSkVRra"
      },
      "source": [
        "Train a model for sigarette detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MSPrRYf-UiIR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import psutil\n",
        "import os\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIwrXGVosy",
        "outputId": "c4cb5924-7c75-44ce-f370-389382c27236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "XMipeipr9n0T"
      },
      "outputs": [],
      "source": [
        "class CigaretteDataset(Dataset):\n",
        "    def __init__(self, coco_annotation_file, image_dir, transform=None):\n",
        "        self.coco = COCO(coco_annotation_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform if transform is not None else transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        cat_ids = self.coco.getCatIds(catNms=['cigarette'])\n",
        "        if not cat_ids:\n",
        "            raise ValueError(\"No 'cigarette' category found in COCO file.\")\n",
        "        self.image_ids = list(set(self.coco.getImgIds(catIds=cat_ids)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.coco.loadImgs(img_id)[0]\n",
        "        image = Image.open(f\"{self.image_dir}/{img_info['file_name']}\").convert(\"RGB\")\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "        annotations = self.coco.loadAnns(ann_ids)\n",
        "        boxes, labels = [], []\n",
        "\n",
        "        for ann in annotations:\n",
        "            cat_name = self.coco.loadCats(ann['category_id'])[0]['name']\n",
        "            x, y, w, h = ann['bbox']\n",
        "\n",
        "            if cat_name == 'cigarette':\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(1)  # Class 1 for 'cigarette'\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([img_id])\n",
        "        }\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zCmmBmSg9n0U"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*[b for b in batch if b is not None]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-W4OPACV9n0V"
      },
      "outputs": [],
      "source": [
        "def check_system_usage():\n",
        "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ny3cwv1_9n0V"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset, device):\n",
        "    print(\"\\n=== Starting Validation ===\")\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    coco_dt = []\n",
        "    coco_gt = dataset.coco\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx in tqdm(range(len(dataset)), desc=\"Validating\", ncols=100):\n",
        "            image, target = dataset[idx]\n",
        "            image = image.to(device).unsqueeze(0)  # Add batch dimension\n",
        "            target = [{k: v.to(device) for k, v in target.items()}]\n",
        "\n",
        "            # During validation, the model should return only predictions, not loss.\n",
        "            predictions = model(image)  # Only predictions during evaluation\n",
        "\n",
        "            # If the model is returning a dictionary with loss values (for training):\n",
        "            if isinstance(predictions, dict):\n",
        "                loss_dict = predictions\n",
        "                loss = sum(loss for loss in loss_dict.values())\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "            # Collect detection results (boxes, labels, scores) for COCO eval:\n",
        "            for box, score, label in zip(predictions[0]['boxes'], predictions[0]['scores'], predictions[0]['labels']):\n",
        "                x1, y1, x2, y2 = box.tolist()\n",
        "                coco_dt.append({\n",
        "                    'image_id': target[0]['image_id'].item(),\n",
        "                    'category_id': label.item(),\n",
        "                    'bbox': [x1, y1, x2 - x1, y2 - y1],  # COCO format [x, y, width, height]\n",
        "                    'score': score.item()\n",
        "                })\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(dataset) if len(dataset) > 0 else 0\n",
        "    print(f\"\\nValidation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # COCO evaluation (optional, if needed):\n",
        "    if len(coco_dt) > 0:\n",
        "        try:\n",
        "            coco_dt = coco_gt.loadRes(coco_dt)\n",
        "            coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
        "            coco_eval.evaluate()\n",
        "            coco_eval.accumulate()\n",
        "            coco_eval.summarize()\n",
        "        except Exception as e:\n",
        "            print(f\"Error during COCO evaluation: {str(e)}\")\n",
        "\n",
        "    print(\"\\n=== Validation Complete ===\\n\")\n",
        "    return avg_val_loss  # Return average validation loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(dataset, num_epochs=10, val_dataset=None, patience=3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Initialize model and move to device\n",
        "    model = fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes=4)\n",
        "    model = model.to(device)\n",
        "\n",
        "    data_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate_fn,\n",
        "        num_workers=2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "    scaler = torch.amp.GradScaler('cuda') if torch.cuda.is_available() else None\n",
        "    epoch_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100, unit=\"batch\")):\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scaler is not None:\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    loss_dict = model(images, targets)\n",
        "                    loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                loss_dict = model(images, targets)\n",
        "                loss = sum(loss for loss in loss_dict.values())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        epoch_losses.append(avg_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "        check_system_usage()\n",
        "\n",
        "        if val_dataset:\n",
        "            val_loss = evaluate_model(model, val_dataset, device)  # Ora val_loss è un float\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            # Early stopping logic\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                epochs_no_improve = 0\n",
        "                best_model_state = model.state_dict()\n",
        "                torch.save({\n",
        "                    'epoch': epoch + 1,\n",
        "                    'model_state_dict': best_model_state,\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': avg_loss\n",
        "                }, 'best_model.pth')\n",
        "                print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(f\"No improvement for {patience} epochs, stopping training.\")\n",
        "                    break\n",
        "        else:\n",
        "            print(\"No validation dataset provided - skipping validation\")\n",
        "\n",
        "        # Save the last epoch model\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_loss\n",
        "        }, 'last_model.pth')\n",
        "        print(f\"Last model saved for epoch {epoch+1}\")\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save(model.state_dict(), f\"fasterrcnn_cigarette_final.pth\")\n",
        "    print(f'Final model saved: fasterrcnn_cigarette_final.pth')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RAM--JDL-2EK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "FTKPIfSe9n0W",
        "outputId": "f697ca3b-ec58-4996-8eeb-d6a2efd03d9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Using device: cuda\n",
            "Starting Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|████████████████████████████████████████████████| 92/92 [01:56<00:00,  1.26s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5134, Time: 116.09s\n",
            "CPU Usage: 68.7%\n",
            "RAM Usage: 53.7%\n",
            "GPU Memory Allocated: 4.09 GB\n",
            "GPU Memory Reserved: 14.13 GB\n",
            "\n",
            "=== Starting Validation ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|█████████████████████████████████████████████████| 142/142 [00:26<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Loss: 0.0000\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=20.97s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.168\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.155\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.039\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.104\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.107\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.319\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.330\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\n",
            "=== Validation Complete ===\n",
            "\n",
            "New best model saved with validation loss: 0.0000\n",
            "Last model saved for epoch 1\n",
            "Starting Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|████████████████████████████████████████████████| 92/92 [01:56<00:00,  1.27s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 0.2258, Time: 116.71s\n",
            "CPU Usage: 79.6%\n",
            "RAM Usage: 45.9%\n",
            "GPU Memory Allocated: 1.61 GB\n",
            "GPU Memory Reserved: 14.13 GB\n",
            "\n",
            "=== Starting Validation ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|█████████████████████████████████████████████████| 142/142 [00:25<00:00,  5.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Loss: 0.0000\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.264\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.340\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.064\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.143\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.430\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\n",
            "=== Validation Complete ===\n",
            "\n",
            "Last model saved for epoch 2\n",
            "Starting Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|████████████████████████████████████████████████| 92/92 [01:54<00:00,  1.25s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 0.1962, Time: 114.94s\n",
            "CPU Usage: 86.7%\n",
            "RAM Usage: 45.7%\n",
            "GPU Memory Allocated: 1.61 GB\n",
            "GPU Memory Reserved: 14.13 GB\n",
            "\n",
            "=== Starting Validation ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|█████████████████████████████████████████████████| 142/142 [00:25<00:00,  5.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Loss: 0.0000\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.20s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.299\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.377\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.466\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.162\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.457\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.573\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\n",
            "=== Validation Complete ===\n",
            "\n",
            "Last model saved for epoch 3\n",
            "Starting Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|████████████████████████████████████████████████| 92/92 [01:55<00:00,  1.26s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 0.1671, Time: 115.63s\n",
            "CPU Usage: 89.4%\n",
            "RAM Usage: 45.9%\n",
            "GPU Memory Allocated: 1.61 GB\n",
            "GPU Memory Reserved: 14.13 GB\n",
            "\n",
            "=== Starting Validation ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|█████████████████████████████████████████████████| 142/142 [00:25<00:00,  5.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation Loss: 0.0000\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.12s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.137\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.080\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.164\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.488\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\n",
            "=== Validation Complete ===\n",
            "\n",
            "No improvement for 3 epochs, stopping training.\n",
            "Final model saved: fasterrcnn_cigarette_final.pth\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #psutil.Process().nice(psutil.BELOW_NORMAL_PRIORITY_CLASS)\n",
        "    train_image_dir = '/content/drive/MyDrive/Photo/train'\n",
        "    train_coco_annotation_file = '/content/drive/MyDrive/Photo/train/_annotations.coco.json'\n",
        "\n",
        "    valid_image_dir = '/content/drive/MyDrive/Photo/valid'\n",
        "    valid_coco_annotation_file = '/content/drive/MyDrive/Photo/valid/_annotations.coco.json'\n",
        "\n",
        "    dataset = CigaretteDataset(train_coco_annotation_file, train_image_dir)\n",
        "    val_dataset = CigaretteDataset(valid_coco_annotation_file, valid_image_dir)\n",
        "\n",
        "    model = train_model(dataset, num_epochs=10, val_dataset= val_dataset, patience= 3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}