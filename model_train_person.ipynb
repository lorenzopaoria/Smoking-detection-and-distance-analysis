{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzopaoria/Smoking-detection-and-distance-analysis/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-6xHSkVRra"
      },
      "source": [
        "Train a model for sigarette detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSPrRYf-UiIR",
        "outputId": "d7890523-25a8-4eb7-eba8-9b8c4c870e11"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import psutil\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZIwrXGVosy",
        "outputId": "e854c683-9a1f-46b0-aff2-934aba00e351"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PP\n",
        "\n",
        "mi deve salvare i pth nella cartella /content/drive/MyDrive/pth_person_detect\n",
        "\n",
        "Ti aiuto a modificare il percorso di salvataggio dei modelli.\n",
        "Claude can make mistakes. Please double-check responses.\n",
        "\n",
        "\n",
        "Smoker Detection Training with YOLOv8\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import psutil\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "class ModelCallback:\n",
        "    def __init__(self, save_dir):\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.best_map = 0\n",
        "        self.training_history = []\n",
        "        \n",
        "    def on_train_epoch_end(self, trainer):\n",
        "        # Get current metrics\n",
        "        metrics = trainer.metrics\n",
        "        epoch = trainer.epoch\n",
        "        \n",
        "        # Extract mAP50-95\n",
        "        current_map = metrics.get('metrics/mAP50-95(B)', 0)\n",
        "        \n",
        "        # Save metrics history\n",
        "        self.training_history.append({\n",
        "            'epoch': epoch,\n",
        "            'mAP': current_map,\n",
        "            'metrics': metrics\n",
        "        })\n",
        "        \n",
        "        # Save history to JSON\n",
        "        with open(self.save_dir / 'training_history.json', 'w') as f:\n",
        "            json.dump(self.training_history, f, indent=4)\n",
        "        \n",
        "        # Save model if it's the best so far\n",
        "        if current_map > self.best_map:\n",
        "            self.best_map = current_map\n",
        "            save_path = self.save_dir / f'best_model_map_{current_map:.4f}.pth'\n",
        "            torch.save(trainer.model.state_dict(), save_path)\n",
        "            \n",
        "            # Save a symlink to the best model\n",
        "            best_link = self.save_dir / 'best_model.pth'\n",
        "            if best_link.exists():\n",
        "                best_link.unlink()\n",
        "            best_link.symlink_to(f'best_model_map_{current_map:.4f}.pth')\n",
        "            \n",
        "        # Always save last model\n",
        "        last_model_path = self.save_dir / f'last_model_epoch_{epoch}.pth'\n",
        "        torch.save(trainer.model.state_dict(), last_model_path)\n",
        "        \n",
        "        # Update symlink to last model\n",
        "        last_link = self.save_dir / 'last_model.pth'\n",
        "        if last_link.exists():\n",
        "            last_link.unlink()\n",
        "        last_link.symlink_to(f'last_model_epoch_{epoch}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_system_usage():\n",
        "    \"\"\"Monitor system resources\"\"\"\n",
        "    print(\"\\nSystem Usage:\")\n",
        "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
        "    print(f\"RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataset_yaml(train_path, val_path, num_classes=2):\n",
        "    \"\"\"Create YAML configuration file for YOLOv8\"\"\"\n",
        "    data = {\n",
        "        'train': train_path,\n",
        "        'val': val_path,\n",
        "        'names': {\n",
        "            0: 'smoker',\n",
        "            1: 'non_smoker'\n",
        "        },\n",
        "        'nc': num_classes\n",
        "    }\n",
        "    \n",
        "    yaml_path = Path('dataset.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(data, f)\n",
        "    \n",
        "    return str(yaml_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_coco_to_yolo(coco_annotation_file, image_dir, output_dir):\n",
        "    \"\"\"Convert COCO format annotations to YOLO format with progress bar\"\"\"\n",
        "    from pycocotools.coco import COCO\n",
        "    \n",
        "    print(f\"\\nLoading COCO annotations from {coco_annotation_file}\")\n",
        "    coco = COCO(coco_annotation_file)\n",
        "    \n",
        "    # Create output directories\n",
        "    output_dir = Path(output_dir)\n",
        "    (output_dir / 'labels').mkdir(parents=True, exist_ok=True)\n",
        "    (output_dir / 'images').mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Get total number of images for progress bar\n",
        "    img_ids = coco.getImgIds()\n",
        "    total_images = len(img_ids)\n",
        "    \n",
        "    print(f\"Converting {total_images} images and annotations...\")\n",
        "    \n",
        "    # Process each image with tqdm progress bar\n",
        "    for img_id in tqdm(img_ids, desc=\"Converting annotations\", unit=\"image\"):\n",
        "        img_info = coco.loadImgs(img_id)[0]\n",
        "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
        "        anns = coco.loadAnns(ann_ids)\n",
        "        \n",
        "        # Prepare paths\n",
        "        label_file = Path(img_info['file_name']).stem + '.txt'\n",
        "        label_path = output_dir / 'labels' / label_file\n",
        "        img_src = Path(image_dir) / img_info['file_name']\n",
        "        img_dst = output_dir / 'images' / img_info['file_name']\n",
        "        \n",
        "        # Copy image\n",
        "        if img_src.exists():\n",
        "            from shutil import copy2\n",
        "            copy2(str(img_src), str(img_dst))\n",
        "        \n",
        "        # Convert annotations\n",
        "        with open(label_path, 'w') as f:\n",
        "            for ann in anns:\n",
        "                # Convert category_id: 0 for smoker, 1 for non_smoker\n",
        "                category_id = 0 if ann['category_id'] == 1 else 1\n",
        "                \n",
        "                # Convert bbox to YOLO format\n",
        "                x, y, w, h = ann['bbox']\n",
        "                x_center = (x + w/2) / img_info['width']\n",
        "                y_center = (y + h/2) / img_info['height']\n",
        "                w = w / img_info['width']\n",
        "                h = h / img_info['height']\n",
        "                \n",
        "                # Write YOLO format line\n",
        "                f.write(f\"{category_id} {x_center} {y_center} {w} {h}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(yaml_path, save_dir, epochs=100, imgsz=640, batch=16):\n",
        "    \"\"\"Train YOLOv8 model with progress monitoring and model saving\"\"\"\n",
        "    print(\"\\nInitializing YOLOv8 model...\")\n",
        "    model = YOLO('yolov8n.pt')\n",
        "    \n",
        "    # Initialize callback with the specified save directory\n",
        "    callback = ModelCallback(save_dir)\n",
        "    \n",
        "    print(\"\\nStarting training...\")\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        batch=batch,\n",
        "        device=0 if torch.cuda.is_available() else 'cpu',\n",
        "        patience=50,  # Early stopping patience\n",
        "        save=True,\n",
        "        project=str(save_dir),\n",
        "        name='train',\n",
        "        exist_ok=True,\n",
        "        callbacks=[callback]\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nTraining completed. Models saved in {save_dir}\")\n",
        "    print(f\"Best mAP: {callback.best_map:.4f}\")\n",
        "    \n",
        "    return model, callback.best_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Smoker Detection Training Pipeline\")\n",
        "    \n",
        "    # Paths\n",
        "    train_image_dir = '/content/drive/MyDrive/Photo/train'\n",
        "    train_coco_annotation_file = '/content/drive/MyDrive/Photo/train/_annotations.coco.json'\n",
        "    valid_image_dir = '/content/drive/MyDrive/Photo/valid'\n",
        "    valid_coco_annotation_file = '/content/drive/MyDrive/Photo/valid/_annotations.coco.json'\n",
        "    \n",
        "    # Set save directory\n",
        "    save_dir = Path('/content/drive/MyDrive/pth_person_detect')\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Add timestamp to create a unique subdirectory for this training run\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_dir = save_dir / f'run_{timestamp}'\n",
        "    \n",
        "    # Convert datasets\n",
        "    print(\"\\nPreparing datasets...\")\n",
        "    convert_coco_to_yolo(train_coco_annotation_file, train_image_dir, 'dataset/train')\n",
        "    convert_coco_to_yolo(valid_coco_annotation_file, valid_image_dir, 'dataset/valid')\n",
        "    \n",
        "    # Create YAML configuration\n",
        "    yaml_path = create_dataset_yaml('dataset/train', 'dataset/valid')\n",
        "    \n",
        "    # Train model\n",
        "    model, best_map = train_model(yaml_path, run_dir, epochs=100)\n",
        "    \n",
        "    # Final system usage check\n",
        "    check_system_usage()\n",
        "    \n",
        "    print(f\"\\nTraining pipeline completed successfully!\")\n",
        "    print(f\"Best model achieved mAP: {best_map:.4f}\")\n",
        "    print(f\"Models saved in: {run_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
